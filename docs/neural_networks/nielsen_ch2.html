<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>56&nbsp; Nielsen’s NNDL, ch.2 – Statistics and Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../misc/trend_test.html" rel="next">
<link href="../neural_networks/nielsen_ch1.html" rel="prev">
<link href="../archive/logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-a588049bcf6ba0aff1d03aeee07a0105.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-2c63ad6a8cffefe8536d13eabcc001d1.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TB8VQN4T5W"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-TB8VQN4T5W', { 'anonymize_ip': true});
</script>
<!-- <link href="//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css" rel="stylesheet">
<script src="https://code.iconify.design/1/1.0.7/iconify.min.js"></script>
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.10.2/css/all.css"> -->

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../neural_networks/nielsen_ch1.html">neural networks</a></li><li class="breadcrumb-item"><a href="../neural_networks/nielsen_ch2.html"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.2</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../archive/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Statistics and Machine Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://yairmau.com/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-house-fill"></i></a>
    <a href="https://github.com/yairmau/statistics/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/height.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">height data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/weight.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">weight data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">hypothesis testing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/t_test_one_sample.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">one-sample t-test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/t_test_independent_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">independent samples t-test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/statistical_power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">statistical power</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/problem-with-t-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">the problem with t-test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/permutation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">permutation test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/numpy-vs-pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">numpy vs pandas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/exact-vs-montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">exact vs.&nbsp;Monte Carlo permutation tests</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">confidence interval</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../confidence_interval/basic_concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">basic concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../confidence_interval/analytical_confidence_interval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">analytical confidence interval</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../confidence_interval/empirical_confidence_interval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">empirical confidence interval</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/geometry-of-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">the geometry of regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/least-squares.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">least squares</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/partitioning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">partitioning of the sum of squares</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/R-squared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">R-squared</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/equivalence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">equivalence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/mixed-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">linear mixed effect model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">logistic regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/logistic_2d.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">logistic 2d</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">correlation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correlation/correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">correlation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correlation/linear_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">correlation and linear regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correlation/cosine.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">cosine</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correlation/significance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">significance (p-value)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/from-the-ground-up.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Bayes’ theorem from the ground up</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/parametric-generative-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">parametric generative classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/odds.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">odds and log likelihood</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/logistic-connection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">logistic connection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/conjugate-prior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">conjugate prior</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/boy-girl-paradox.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">the boy-girl paradox</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/monty-hall.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">monty hall</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">svd and pca</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../svd_and_pca/svd_image_compression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">SVD for image compression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../svd_and_pca/svd_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">SVD for regression</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">decision trees</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../decision_trees/CART_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">CART: classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../decision_trees/CART_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">CART: regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../decision_trees/random_forest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">random forest</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">information theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../information_theory/entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">entropy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../information_theory/cross-entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">cross-entropy and KL divergence</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">likelihood</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/probability_and_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">probability and likelihood</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">maximum likelihood estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_summary_statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">MLE and summary statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_linear_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">MLE and linear regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_information_theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">MLE and information theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">MLE and regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">MLE and classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_bayesian_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">MLE and bayesian inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">generalization and model complexity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/motivation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">motivation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">bias-variance tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/overfitting-and-underfitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">overfitting and underfitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/cross-validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">cross-validation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/data-splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">data splitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/more-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">when more data changes the tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/double-descent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">double descent</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">neural networks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../neural_networks/nielsen_ch1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../neural_networks/nielsen_ch2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.2</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">miscellaneous</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../misc/trend_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">trend test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../misc/shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">SHAP values</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#derivation" id="toc-derivation" class="nav-link active" data-scroll-target="#derivation"><span class="header-section-number">56.1</span> derivation</a>
  <ul class="collapse">
  <li><a href="#cost" id="toc-cost" class="nav-link" data-scroll-target="#cost"><span class="header-section-number">56.1.1</span> cost</a></li>
  <li><a href="#rule-for-updating-the-parameters" id="toc-rule-for-updating-the-parameters" class="nav-link" data-scroll-target="#rule-for-updating-the-parameters"><span class="header-section-number">56.1.2</span> rule for updating the parameters</a></li>
  <li><a href="#the-structure-of-the-argument" id="toc-the-structure-of-the-argument" class="nav-link" data-scroll-target="#the-structure-of-the-argument"><span class="header-section-number">56.1.3</span> the structure of the argument</a></li>
  </ul></li>
  <li><a href="#the-error" id="toc-the-error" class="nav-link" data-scroll-target="#the-error"><span class="header-section-number">56.2</span> the “error”</a></li>
  <li><a href="#base-case-the-output-layer" id="toc-base-case-the-output-layer" class="nav-link" data-scroll-target="#base-case-the-output-layer"><span class="header-section-number">56.3</span> base case: the output layer</a></li>
  <li><a href="#the-inductive-step-the-hidden-layers" id="toc-the-inductive-step-the-hidden-layers" class="nav-link" data-scroll-target="#the-inductive-step-the-hidden-layers"><span class="header-section-number">56.4</span> the inductive step: the hidden layers</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">56.5</span> summary</a></li>
  <li><a href="#batches" id="toc-batches" class="nav-link" data-scroll-target="#batches"><span class="header-section-number">56.6</span> batches</a></li>
  <li><a href="#vectorizing-nielsens-backpropagation-code" id="toc-vectorizing-nielsens-backpropagation-code" class="nav-link" data-scroll-target="#vectorizing-nielsens-backpropagation-code"><span class="header-section-number">56.7</span> vectorizing Nielsen’s backpropagation code</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../neural_networks/nielsen_ch1.html">neural networks</a></li><li class="breadcrumb-item"><a href="../neural_networks/nielsen_ch2.html"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.2</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.2</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button" data-quarto-source-url="https://github.com/yairmau/statistics/blob/main/neural_networks/nielsen_ch2.ipynb">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>I’m not sure I have something new to add to the vast number of explanations on backpropagation found on the internet. Almost certainly I don’t. However, I can only truly grasp a concept if I work it out myself, and that’s what this chapter is about. I found <a href="https://www.youtube.com/watch?v=VMj-3S1tku0">Andrej Karpathy’s youtube video</a> on micrograd very useful. He really takes the time to explain the mechanics behind backpropagation. Another useful source was <a href="https://youtu.be/Ilg3gGewQ5U?si=4q294k85uvQfBucz">3b1b youtube videos</a>. It’s obvious that he’s restating Nielsen’s arguments, but with greater pedagogical clarity and superb visualizations. With regard to Nielsen’s approach, I personally hated that he first showed the end form of the equations, and only at the very end of the chapter went about deriving them. At the outset, he says about the first equation “This is a very natural expression”. Personally I found nothing natural until I fully understood the derivation. Also, the order of the equations is wrong: what we really need are equations 3 and 4, and equations 1 and 2 are the means to calculate what we need. Nielsen, if you’re reading this, know that this criticism comes from a place of love, you did a great service to humanity. I’ll stop ranting now, and I’ll derive backpropagation myself. If you don’t quite get it, it’s probably because I’m writing to someone who I assumed to have read Nielsen’s book (which you should).</p>
<section id="derivation" class="level2" data-number="56.1">
<h2 data-number="56.1" class="anchored" data-anchor-id="derivation"><span class="header-section-number">56.1</span> derivation</h2>
<section id="cost" class="level3" data-number="56.1.1">
<h3 data-number="56.1.1" class="anchored" data-anchor-id="cost"><span class="header-section-number">56.1.1</span> cost</h3>
<p>We start with the cost function. For one given input <span class="math inline">x</span> (one photo of a digit in our dataset), we run our neural network with the usual feed forward algorithm, and get the vector of activations <span class="math inline">a</span> at the last layer <span class="math inline">L</span>. The cost then will be</p>
<p><span class="math display">
C_x = \frac{1}{2} \sum_j \left( y_j - a^L_j\right)^2.
</span></p>
<p>The one half has no special significance here, it will just make life a bit easier in the future, once we take the derivative of the cost. But let’s not get distracted.</p>
<p>We sum over <span class="math inline">j</span>, the index counting the number of neurons in the output layer, which in our case is 10. <span class="math inline">y_j</span> represents the one-hot label of the digit in <span class="math inline">x</span>. For instance, for the digit <span class="math inline">3</span> we might get something like that:</p>
<p><span class="math display">
y =
\begin{bmatrix}
0\\0\\0\\1\\0\\0\\0\\0\\0\\0
\end{bmatrix},
\quad
a^L =
\begin{bmatrix}
0.1\\0.7\\0.0\\0.5\\0.4\\0.6\\0.1\\0.0\\0.1\\0.6
\end{bmatrix},
\quad
(y-a^L)^2 =
\begin{bmatrix}
0.01\\0.49\\0.0\\0.25\\0.16\\0.36\\0.01\\0.0\\0.01\\0.36
\end{bmatrix}.
</span></p>
<p>Then <span class="math inline">C_x</span> is just half of the sum of this last vector. So far so good. But what about all the other thousands of input images? We do the same for them, and get the total cost for our entire dataset:</p>
<p><span class="math display">
C = \frac{1}{n}\sum_x C_x
</span></p>
</section>
<section id="rule-for-updating-the-parameters" class="level3" data-number="56.1.2">
<h3 data-number="56.1.2" class="anchored" data-anchor-id="rule-for-updating-the-parameters"><span class="header-section-number">56.1.2</span> rule for updating the parameters</h3>
<p>Our goal is to update each and every weight and bias in our neural network, so to decrease as much as we can this cost. The lower the cost, the more accurate will be our number classification.</p>
<p>This cost lives in a multi-dimensional space. By the gradient descent method, we take a tiny step in the parameter space in the direction opposite to the gradient of the cost. If <span class="math inline">p</span> is to represent our parameter vector, than we would write</p>
<p><span class="math display">
p_\text{new} = p_\text{old} - \eta \nabla C,
</span></p>
<p>where <span class="math inline">\eta</span> is the learning rate.</p>
<p>Each element of <span class="math inline">p</span> is a weight or bias in the network. Now is the right time to be precise and refer specifically to each parameter, and first we need a good mental model for the parameters.</p>
<div id="898770e0" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>import libraries</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> io</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> gzip</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> requests</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> patches</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="818c90ce" class="cell" data-execution_count="89">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a>layer_left <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>layer_center <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>layer_right <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>layer_right2 <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb2-7"><a href="#cb2-7"></a></span>
<span id="cb2-8"><a href="#cb2-8"></a>layers <span class="op">=</span> [layer_left, layer_center, layer_right, layer_right2]</span>
<span id="cb2-9"><a href="#cb2-9"></a></span>
<span id="cb2-10"><a href="#cb2-10"></a></span>
<span id="cb2-11"><a href="#cb2-11"></a></span>
<span id="cb2-12"><a href="#cb2-12"></a></span>
<span id="cb2-13"><a href="#cb2-13"></a>weights <span class="op">=</span> []</span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="cf">for</span> l, layer <span class="kw">in</span> <span class="bu">enumerate</span>(layers[:<span class="op">-</span><span class="dv">1</span>]):</span>
<span id="cb2-15"><a href="#cb2-15"></a>    weights.append(np.ones((layers[l<span class="op">+</span><span class="dv">1</span>], layer)))</span>
<span id="cb2-16"><a href="#cb2-16"></a></span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="cf">for</span> l,w <span class="kw">in</span> <span class="bu">enumerate</span>(weights):</span>
<span id="cb2-18"><a href="#cb2-18"></a>    x_left <span class="op">=</span> l</span>
<span id="cb2-19"><a href="#cb2-19"></a>    x_right <span class="op">=</span> l<span class="op">+</span><span class="dv">1</span><span class="op">-</span><span class="fl">0.2</span></span>
<span id="cb2-20"><a href="#cb2-20"></a>    x_b <span class="op">=</span> l<span class="op">+</span><span class="dv">1</span></span>
<span id="cb2-21"><a href="#cb2-21"></a>    <span class="cf">for</span> index, value <span class="kw">in</span> np.ndenumerate(w):</span>
<span id="cb2-22"><a href="#cb2-22"></a>        y_right <span class="op">=</span> index[<span class="dv">0</span>] <span class="op">-</span> layers[l<span class="op">+</span><span class="dv">1</span>]<span class="op">/</span><span class="dv">2</span></span>
<span id="cb2-23"><a href="#cb2-23"></a>        y_left <span class="op">=</span> index[<span class="dv">1</span>] <span class="op">-</span> layers[l]<span class="op">/</span><span class="dv">2</span></span>
<span id="cb2-24"><a href="#cb2-24"></a>        zorder <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb2-25"><a href="#cb2-25"></a>        <span class="cf">if</span> (l<span class="op">==</span><span class="dv">0</span> <span class="kw">and</span> index[<span class="dv">0</span>]<span class="op">==</span><span class="dv">4</span>):</span>
<span id="cb2-26"><a href="#cb2-26"></a>            color <span class="op">=</span> <span class="st">"xkcd:cerulean"</span></span>
<span id="cb2-27"><a href="#cb2-27"></a>        <span class="cf">elif</span> (l<span class="op">==</span><span class="dv">1</span> <span class="kw">and</span> index[<span class="dv">0</span>]<span class="op">==</span><span class="dv">0</span>):</span>
<span id="cb2-28"><a href="#cb2-28"></a>            color <span class="op">=</span> <span class="st">"xkcd:vermillion"</span></span>
<span id="cb2-29"><a href="#cb2-29"></a>        <span class="cf">elif</span> (l<span class="op">==</span><span class="dv">2</span> <span class="kw">and</span> index[<span class="dv">0</span>]<span class="op">==</span>layers[l<span class="op">+</span><span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb2-30"><a href="#cb2-30"></a>            color <span class="op">=</span> <span class="st">"xkcd:barney"</span></span>
<span id="cb2-31"><a href="#cb2-31"></a>            ax.text(x_b<span class="op">-</span><span class="fl">0.5</span>, np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span> <span class="op">-</span> <span class="fl">0.2</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">w_</span><span class="ch">{{</span><span class="vs">0j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span>color, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-32"><a href="#cb2-32"></a>            ax.text(x_b<span class="op">-</span><span class="fl">0.15</span>, np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span> <span class="op">+</span><span class="fl">0.1</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">b_</span><span class="ch">{{</span><span class="op">0</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span>color, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-33"><a href="#cb2-33"></a>            ax.text(x_b<span class="op">+</span><span class="fl">0.6</span>, np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span> <span class="op">-</span> <span class="fl">1.5</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">z_</span><span class="ch">{{</span><span class="op">0</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="sc">}</span><span class="vs"> = w_</span><span class="ch">{{</span><span class="vs">0j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="sc">}</span><span class="er">\</span><span class="vs">cdot a_</span><span class="ch">{{</span><span class="vs">j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="vs"> </span><span class="op">+</span><span class="vs"> b_</span><span class="ch">{{</span><span class="op">0</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span>color, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-34"><a href="#cb2-34"></a>            ax.text(x_b<span class="op">-</span><span class="dv">1</span>, (layers[<span class="dv">2</span>])<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">a_</span><span class="ch">{{</span><span class="vs">j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span>color, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-35"><a href="#cb2-35"></a>        <span class="cf">else</span>: color <span class="op">=</span> [<span class="fl">0.8</span>]<span class="op">*</span><span class="dv">3</span><span class="op">;</span> zorder <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-36"><a href="#cb2-36"></a>        ax.plot([x_left, x_right], [y_left, y_right], color<span class="op">=</span>color, zorder<span class="op">=</span>zorder)</span>
<span id="cb2-37"><a href="#cb2-37"></a>        ax.plot([x_b, x_right], [y_right, y_right], color<span class="op">=</span>color, zorder<span class="op">=</span>zorder)</span>
<span id="cb2-38"><a href="#cb2-38"></a></span>
<span id="cb2-39"><a href="#cb2-39"></a>ms <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb2-40"><a href="#cb2-40"></a><span class="cf">for</span> l, layer <span class="kw">in</span> <span class="bu">enumerate</span>(layers):</span>
<span id="cb2-41"><a href="#cb2-41"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer):</span>
<span id="cb2-42"><a href="#cb2-42"></a>        ax.plot([l], [i <span class="op">-</span> layer<span class="op">/</span><span class="dv">2</span>], ls<span class="op">=</span><span class="st">'None'</span>, marker<span class="op">=</span><span class="st">'o'</span>, mfc<span class="op">=</span><span class="st">"white"</span>, mec<span class="op">=</span><span class="st">"black"</span>, markersize<span class="op">=</span>ms,</span>
<span id="cb2-43"><a href="#cb2-43"></a>                color<span class="op">=</span><span class="st">"gray"</span>, lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">1.0</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-44"><a href="#cb2-44"></a>        ax.text(l, i <span class="op">-</span> layer<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.05</span>, <span class="ss">f"</span><span class="sc">{</span>layer<span class="op">-</span>i<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">10</span>, color<span class="op">=</span><span class="st">"gray"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-45"><a href="#cb2-45"></a>        <span class="cf">if</span> l <span class="op">==</span><span class="dv">0</span>:</span>
<span id="cb2-46"><a href="#cb2-46"></a>            ax.text(l, <span class="op">-</span>np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="ss">f"input layer"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"gray"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-47"><a href="#cb2-47"></a>        <span class="cf">if</span> l <span class="op">&gt;=</span><span class="dv">1</span>:</span>
<span id="cb2-48"><a href="#cb2-48"></a>            ax.text(l, <span class="op">-</span>np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="ss">f"layer </span><span class="sc">{</span>l<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"gray"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-49"><a href="#cb2-49"></a>        </span>
<span id="cb2-50"><a href="#cb2-50"></a><span class="co"># for i in range(layer_left):</span></span>
<span id="cb2-51"><a href="#cb2-51"></a><span class="co">#     for j in range(layer_right):</span></span>
<span id="cb2-52"><a href="#cb2-52"></a><span class="co">#         if i == 2:</span></span>
<span id="cb2-53"><a href="#cb2-53"></a><span class="co">#             color = "xkcd:cerulean"</span></span>
<span id="cb2-54"><a href="#cb2-54"></a><span class="co">#             alpha = 1.0</span></span>
<span id="cb2-55"><a href="#cb2-55"></a><span class="co">#         else:</span></span>
<span id="cb2-56"><a href="#cb2-56"></a><span class="co">#             alpha = 0.5</span></span>
<span id="cb2-57"><a href="#cb2-57"></a><span class="co">#             color = "gray"</span></span>
<span id="cb2-58"><a href="#cb2-58"></a><span class="co">#         ax.plot([0, 1], [(layer_left - i)/layer_left, (layer_right - j + 1.5)/layer_left], </span></span>
<span id="cb2-59"><a href="#cb2-59"></a><span class="co">#                 color=color, lw=2, alpha=alpha)</span></span>
<span id="cb2-60"><a href="#cb2-60"></a>        </span>
<span id="cb2-61"><a href="#cb2-61"></a></span>
<span id="cb2-62"><a href="#cb2-62"></a><span class="co"># for i in range(layer_left):</span></span>
<span id="cb2-63"><a href="#cb2-63"></a><span class="co">#     if i == 2:</span></span>
<span id="cb2-64"><a href="#cb2-64"></a><span class="co">#         color = "xkcd:vermillion"</span></span>
<span id="cb2-65"><a href="#cb2-65"></a><span class="co">#         alpha = 1.0</span></span>
<span id="cb2-66"><a href="#cb2-66"></a><span class="co">#     else:</span></span>
<span id="cb2-67"><a href="#cb2-67"></a><span class="co">#         color = "white"</span></span>
<span id="cb2-68"><a href="#cb2-68"></a><span class="co">#         alpha = 1.0</span></span>
<span id="cb2-69"><a href="#cb2-69"></a><span class="co">#     ax.plot([0], [(layer_left - i)/layer_left], ls='None', marker='o', mfc=color, </span></span>
<span id="cb2-70"><a href="#cb2-70"></a><span class="co">#             mec="gray", markersize=ms, alpha=alpha)</span></span>
<span id="cb2-71"><a href="#cb2-71"></a><span class="co">#     ax.text(-0.1, (layer_left - i)/layer_left, fr"$\delta_{i}^\ell$", </span></span>
<span id="cb2-72"><a href="#cb2-72"></a><span class="co">#                 va='center', ha='right', fontsize=12, color="gray")</span></span>
<span id="cb2-73"><a href="#cb2-73"></a>    </span>
<span id="cb2-74"><a href="#cb2-74"></a><span class="co"># for i in range(layer_right):</span></span>
<span id="cb2-75"><a href="#cb2-75"></a><span class="co">#     color = "xkcd:goldenrod"</span></span>
<span id="cb2-76"><a href="#cb2-76"></a><span class="co">#     ax.plot([1], [(layer_right - i + 1.5)/layer_left], ls='None', marker='o', mfc=color, </span></span>
<span id="cb2-77"><a href="#cb2-77"></a><span class="co">#             mec="gray", markersize=ms)</span></span>
<span id="cb2-78"><a href="#cb2-78"></a><span class="co">#     ax.text(1.1, (layer_right - i + 1.5)/layer_left, fr"$\delta_{i}^{{\ell+1}}$", </span></span>
<span id="cb2-79"><a href="#cb2-79"></a><span class="co">#                 va='center', ha='left', fontsize=12, color="gray")</span></span>
<span id="cb2-80"><a href="#cb2-80"></a></span>
<span id="cb2-81"><a href="#cb2-81"></a><span class="co"># ax.text(0.5, 0.9, r"$w_{ij}$", fontsize=12, color="gray")</span></span>
<span id="cb2-82"><a href="#cb2-82"></a><span class="co"># ax.text(0, 0, r"layer $\ell$", va="top", ha="center", fontsize=14)</span></span>
<span id="cb2-83"><a href="#cb2-83"></a><span class="co"># ax.text(1, 0, r"layer $\ell+1$", va="top", ha="center", fontsize=14)</span></span>
<span id="cb2-84"><a href="#cb2-84"></a></span>
<span id="cb2-85"><a href="#cb2-85"></a>ax.<span class="bu">set</span>(xlim<span class="op">=</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="dv">4</span>), ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">4</span>), xticks<span class="op">=</span>[], yticks<span class="op">=</span>[])</span>
<span id="cb2-86"><a href="#cb2-86"></a><span class="co"># ax.set_aspect('equal')</span></span>
<span id="cb2-87"><a href="#cb2-87"></a><span class="co"># ax.axis('off');</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="nielsen_ch2_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="aaeefc82" class="cell" data-execution_count="33">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>stam <span class="op">=</span> rng.normal(size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">4</span>))</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="cf">for</span> index, value <span class="kw">in</span> np.ndenumerate(stam):</span>
<span id="cb3-3"><a href="#cb3-3"></a>    <span class="bu">print</span>(index, value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(0, 0) -0.43643524714322124
(0, 1) -1.169801907772864
(0, 2) 1.739367877130134
(0, 3) -0.4959107284421519
(1, 0) 0.3289696294602021
(1, 1) -0.258572545473924
(1, 2) 1.5834728788021222
(1, 3) 1.3203609870818391
(2, 0) 0.6333526228249152
(2, 1) -2.2035098806466507
(2, 2) 0.05202897425988651
(2, 3) 0.6836861907765345</code></pre>
</div>
</div>
<p>Translating the equation above to a generic weight and bias term gives:</p>
<p><span class="math display">\begin{align*}
w_\text{new} &amp;= w_\text{old} - \eta \frac{\partial C}{\partial w_\text{old}} \\ \\
b_\text{new} &amp;= b_\text{old} - \eta \frac{\partial C}{\partial b_\text{old}}.
\end{align*}</span></p>
<p>In order to talk about specific weights and biases, we need to introduce indices, but for now that would be a distraction.</p>
<p>Now that we have the rule to update our parameters, “all we have to do” is to figure out the partial derivatives in the equations above.</p>
</section>
<section id="the-structure-of-the-argument" class="level3" data-number="56.1.3">
<h3 data-number="56.1.3" class="anchored" data-anchor-id="the-structure-of-the-argument"><span class="header-section-number">56.1.3</span> the structure of the argument</h3>
<p>The backpropagation algorithm is at its essence an induction.</p>
<ol type="1">
<li>We can find out the partial derivatives for the very last layer, the output layer. This is the Base Case.</li>
<li>We can show that given the partial derivatives in any given layer <span class="math inline">\ell</span>, we can figure out what the partial derivatives are in the layer that precedes it, <span class="math inline">\ell-1</span>. This is the Inductive Step.</li>
<li>That’s it. Starting from the last layer, we can work our way out to the first layer. That explains the name of the algorithm, we’re backpropagating the information, from last to first.</li>
</ol>
</section>
</section>
<section id="the-error" class="level2" data-number="56.2">
<h2 data-number="56.2" class="anchored" data-anchor-id="the-error"><span class="header-section-number">56.2</span> the “error”</h2>
<p>In the previous chapter we defined the weighted input <span class="math inline">z</span> as</p>
<p><span class="math display">
z = w\cdot a + b.
</span></p>
<p>Now is the time to be more precise and introduce indices:</p>
<p><span class="math display">
z^\ell_j = \sum_k w^\ell_{jk} a^{\ell-1}_k + b^\ell_j.
</span></p>
<p>Let’s understand the indices. The superscript <span class="math inline">\ell</span> indicates the layer we’re talking about. The activation <span class="math inline">a</span> receives the superscript <span class="math inline">\ell-1</span> because it belongs to the previous layer. The weight <span class="math inline">w</span> has two subscripts, <span class="math inline">j</span> and <span class="math inline">k</span>, because it connects the <span class="math inline">k</span>th neuron in layer <span class="math inline">\ell-1</span> to the <span class="math inline">j</span>th neuron in layer <span class="math inline">\ell</span>. The bias <span class="math inline">b</span> has only one subscript, <span class="math inline">j</span>, because it belongs to the <span class="math inline">j</span>th neuron in layer <span class="math inline">\ell</span>.</p>
<p>For a given weight or bias, let’s use the chain rule to begin unfolding the partial derivatives we need to find out.</p>
<p><span class="math display">\begin{align*}
\frac{\partial C}{\partial w^\ell_{jk}} &amp;= \left( \frac{\partial C}{\partial z^\ell_j} \right) \frac{\partial z^\ell_j}{\partial w^\ell_{jk}} = \left( \frac{\partial C}{\partial z^\ell_j} \right) a^{\ell-1}_k  \\ \\
\frac{\partial C}{\partial b^\ell_j} &amp;= \left(\frac{\partial C}{\partial z^\ell_j}\right) \frac{\partial z^\ell_j}{\partial b^\ell_j} = \left( \frac{\partial C}{\partial z^\ell_j} \right).
\end{align*}</span></p>
<p>This is great, now both terms look almost the same! We found that we need to calculate the quantity in the parentheses, which we will call the error:</p>
<p><span class="math display">
\delta^\ell_j =\frac{\partial C}{\partial z^\ell_j}
</span></p>
<p>The equation above asks: how sensitive is the total cost <span class="math inline">C</span> to tiny variations in a specific weighted input <span class="math inline">z</span> at the <span class="math inline">j</span>th neuron in layer <span class="math inline">\ell</span>.</p>
<p>Let’s compute this error for the last layer <span class="math inline">L</span>, and lay out the Base Case of our induction.</p>
</section>
<section id="base-case-the-output-layer" class="level2" data-number="56.3">
<h2 data-number="56.3" class="anchored" data-anchor-id="base-case-the-output-layer"><span class="header-section-number">56.3</span> base case: the output layer</h2>
<p>The last layer has index <span class="math inline">L</span>, and the error for the <span class="math inline">j</span>th neuron in this layer is <span class="math display">
\delta^L_j = \frac{\partial C}{\partial z^L_j}.
</span></p>
<p>Let’s use the chain rule to unfold this derivative:</p>
<p><span class="math display">
\delta^L_j = \frac{\partial C}{\partial a^L_j} \frac{\partial a^L_j}{\partial z^L_j}.
</span></p>
<p>Remember that the activation <span class="math inline">a</span> is simply</p>
<p><span class="math display">
a = \sigma(z),
</span></p>
<p>so we have that <span class="math inline">\partial a/\partial z=\sigma'(z)</span>. Rewriting the error gives</p>
<p><span class="math display">
\delta^L_j = \frac{\partial C}{\partial a^L_j} \cdot \sigma'(z^L_j).
</span></p>
<p>We’re in luck, because each of the two terms in the right hand side of the equation above is easy to calculate. The first term is</p>
<p><span class="math display">\begin{align*}
\frac{\partial C}{\partial a^L_j} &amp;= \frac{\partial}{\partial a^L_j} \left[ \frac{1}{n}\sum_x \frac{1}{2} \sum_j \left( y_j - a^L_j\right)^2 \right] \\
&amp;=
\frac{1}{n}\sum_x \sum_j \left( y_j - a^L_j\right).
\end{align*}</span></p>
<p>Let’s translate that into words: the first term is simply the difference <span class="math inline">\left( y_j - a^L_j\right)</span>, summed over all neurons <span class="math inline">j</span> in the output layer, and averaged over all input images <span class="math inline">x</span>. That’s super easy to compute! Let’s see the second term:</p>
<p><span class="math display">
\sigma'(z^L_j)
</span></p>
<p>The derivative of <span class="math inline">\sigma</span> depends on the specific function we choose. Let’s calculate what the answer would be for two commonly used activation functions, the sigmoid and relu. For the sigmoid:</p>
<p><span class="math display">\begin{align*}
\sigma(z) &amp;= \frac{1}{1+\exp(-z)} \\
\sigma'(z) &amp;= \sigma(z)\left(1-\sigma(z)\right).
\end{align*}</span></p>
<p>For the relu:</p>
<p><span class="math display">\begin{align*}
\sigma(z) &amp;= \max(0,z) \\
\sigma'(z) &amp;= \begin{cases}
0 &amp; z &lt; 0 \\
1 &amp; z &gt; 0
\end{cases}
\end{align*}</span></p>
<p>In either case, the derivative is easy to compute, and we have the Base Case of our induction.</p>
</section>
<section id="the-inductive-step-the-hidden-layers" class="level2" data-number="56.4">
<h2 data-number="56.4" class="anchored" data-anchor-id="the-inductive-step-the-hidden-layers"><span class="header-section-number">56.4</span> the inductive step: the hidden layers</h2>
<p>The arguments here are also based on a bunch of partial derivatives and the chain rule. We start from the error in a generic layer <span class="math inline">\ell</span>:</p>
<p><span class="math display">
\delta^\ell_j = \frac{\partial C}{\partial z^\ell_j}.
</span></p>
<p>This error is influenced by the errors in the next layer <span class="math inline">\ell+1</span>, so we now use the chain rule to express this relationship:</p>
<p><span class="math display">
\delta^\ell_j = \sum_k \frac{\partial C}{\partial z^{\ell+1}_k} \frac{\partial z^{\ell+1}_k}{\partial z^\ell_j} = \underbrace{\sum_k \delta^{\ell+1}_k \frac{\partial z^{\ell+1}_k}{\partial z^\ell_j}}_{\text{summation over layer $\ell+1$}}.
</span></p>
<p>Let’s interpret this equation, using the image below to help us. We are already used to the idea that the activation of a neuron in layer <span class="math inline">\ell</span> propagates to the next layer <span class="math inline">\ell+1</span>, from left to right. This is what the blue lines in the image below represent.</p>
<p>The conceptual jump now is to use these same lines to understand how the error in layer <span class="math inline">\ell+1</span> <strong>propagates back</strong> to layer <span class="math inline">\ell</span>, from right to left. The equation above says that the error in layer <span class="math inline">\ell</span> is the sum of the errors in layer <span class="math inline">\ell+1</span>, weighted by something that should be related to the strength of the connection between the neurons in layer <span class="math inline">\ell</span> and layer <span class="math inline">\ell+1</span>.</p>
<div id="7eeadace" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a>layer_left <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>layer_right <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb5-5"><a href="#cb5-5"></a>ms <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer_left):</span>
<span id="cb5-7"><a href="#cb5-7"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(layer_right):</span>
<span id="cb5-8"><a href="#cb5-8"></a>        <span class="cf">if</span> i <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb5-9"><a href="#cb5-9"></a>            color <span class="op">=</span> <span class="st">"xkcd:cerulean"</span></span>
<span id="cb5-10"><a href="#cb5-10"></a>            alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb5-11"><a href="#cb5-11"></a>        <span class="cf">else</span>:</span>
<span id="cb5-12"><a href="#cb5-12"></a>            alpha <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb5-13"><a href="#cb5-13"></a>            color <span class="op">=</span> <span class="st">"gray"</span></span>
<span id="cb5-14"><a href="#cb5-14"></a>        ax.plot([<span class="dv">0</span>, <span class="dv">1</span>], [(layer_left <span class="op">-</span> i)<span class="op">/</span>layer_left, (layer_right <span class="op">-</span> j <span class="op">+</span> <span class="fl">1.5</span>)<span class="op">/</span>layer_left], </span>
<span id="cb5-15"><a href="#cb5-15"></a>                color<span class="op">=</span>color, lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb5-16"><a href="#cb5-16"></a>        </span>
<span id="cb5-17"><a href="#cb5-17"></a></span>
<span id="cb5-18"><a href="#cb5-18"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer_left):</span>
<span id="cb5-19"><a href="#cb5-19"></a>    <span class="cf">if</span> i <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb5-20"><a href="#cb5-20"></a>        color <span class="op">=</span> <span class="st">"xkcd:vermillion"</span></span>
<span id="cb5-21"><a href="#cb5-21"></a>        alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb5-22"><a href="#cb5-22"></a>    <span class="cf">else</span>:</span>
<span id="cb5-23"><a href="#cb5-23"></a>        color <span class="op">=</span> <span class="st">"white"</span></span>
<span id="cb5-24"><a href="#cb5-24"></a>        alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb5-25"><a href="#cb5-25"></a>    ax.plot([<span class="dv">0</span>], [(layer_left <span class="op">-</span> i)<span class="op">/</span>layer_left], ls<span class="op">=</span><span class="st">'None'</span>, marker<span class="op">=</span><span class="st">'o'</span>, mfc<span class="op">=</span>color, </span>
<span id="cb5-26"><a href="#cb5-26"></a>            mec<span class="op">=</span><span class="st">"gray"</span>, markersize<span class="op">=</span>ms, alpha<span class="op">=</span>alpha)</span>
<span id="cb5-27"><a href="#cb5-27"></a>    ax.text(<span class="op">-</span><span class="fl">0.1</span>, (layer_left <span class="op">-</span> i)<span class="op">/</span>layer_left, <span class="vs">fr"</span><span class="dv">$\d</span><span class="vs">elta_</span><span class="sc">{</span>i<span class="sc">}</span><span class="dv">^</span><span class="er">\</span><span class="vs">ell</span><span class="dv">$</span><span class="vs">"</span>, </span>
<span id="cb5-28"><a href="#cb5-28"></a>                va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'right'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb5-29"><a href="#cb5-29"></a>    </span>
<span id="cb5-30"><a href="#cb5-30"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer_right):</span>
<span id="cb5-31"><a href="#cb5-31"></a>    color <span class="op">=</span> <span class="st">"xkcd:goldenrod"</span></span>
<span id="cb5-32"><a href="#cb5-32"></a>    ax.plot([<span class="dv">1</span>], [(layer_right <span class="op">-</span> i <span class="op">+</span> <span class="fl">1.5</span>)<span class="op">/</span>layer_left], ls<span class="op">=</span><span class="st">'None'</span>, marker<span class="op">=</span><span class="st">'o'</span>, mfc<span class="op">=</span>color, </span>
<span id="cb5-33"><a href="#cb5-33"></a>            mec<span class="op">=</span><span class="st">"gray"</span>, markersize<span class="op">=</span>ms)</span>
<span id="cb5-34"><a href="#cb5-34"></a>    ax.text(<span class="fl">1.1</span>, (layer_right <span class="op">-</span> i <span class="op">+</span> <span class="fl">1.5</span>)<span class="op">/</span>layer_left, <span class="vs">fr"</span><span class="dv">$\d</span><span class="vs">elta_</span><span class="sc">{</span>i<span class="sc">}</span><span class="dv">^</span><span class="ch">{{</span><span class="er">\</span><span class="vs">ell</span><span class="op">+</span><span class="vs">1</span><span class="ch">}}</span><span class="dv">$</span><span class="vs">"</span>, </span>
<span id="cb5-35"><a href="#cb5-35"></a>                va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'left'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb5-36"><a href="#cb5-36"></a></span>
<span id="cb5-37"><a href="#cb5-37"></a><span class="co"># ax.text(0.5, 0.9, r"$w_{ij}$", fontsize=12, color="gray")</span></span>
<span id="cb5-38"><a href="#cb5-38"></a>ax.text(<span class="dv">0</span>, <span class="dv">0</span>, <span class="vs">r"layer </span><span class="dv">$</span><span class="er">\</span><span class="vs">ell</span><span class="dv">$</span><span class="vs">"</span>, va<span class="op">=</span><span class="st">"top"</span>, ha<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb5-39"><a href="#cb5-39"></a>ax.text(<span class="dv">1</span>, <span class="dv">0</span>, <span class="vs">r"layer </span><span class="dv">$</span><span class="er">\</span><span class="vs">ell</span><span class="op">+</span><span class="vs">1</span><span class="dv">$</span><span class="vs">"</span>, va<span class="op">=</span><span class="st">"top"</span>, ha<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb5-40"><a href="#cb5-40"></a></span>
<span id="cb5-41"><a href="#cb5-41"></a>ax.<span class="bu">set</span>(xlim<span class="op">=</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.5</span>), ylim<span class="op">=</span>(<span class="dv">0</span>, <span class="fl">1.1</span>), xticks<span class="op">=</span>[], yticks<span class="op">=</span>[])</span>
<span id="cb5-42"><a href="#cb5-42"></a>ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb5-43"><a href="#cb5-43"></a>ax.axis(<span class="st">'off'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="nielsen_ch2_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We need now to evaluate the term</p>
<p><span class="math display">
\frac{\partial z^{\ell+1}_k}{\partial z^\ell_j}.
</span></p>
<p>Remember that the weighted input <span class="math inline">z</span>, at the <span class="math inline">k</span>-th neuron in layer <span class="math inline">\ell+1</span>, is defined as</p>
<p><span class="math display">
z^{\ell+1}_k = \sum_j w_{kj}^{\ell+1} a^\ell_j + b_k^{\ell+1}.
</span></p>
<p>Remember also that the activation <span class="math inline">a</span> is a function of the weighted input <span class="math inline">z</span>, <span class="math inline">a = \sigma(z)</span>. Putting all this together gives</p>
<p><span class="math display">\begin{align*}
\frac{\partial z^{\ell+1}_k}{\partial z^\ell_j} &amp;= \frac{\partial z^{\ell+1}_k}{\partial a^\ell_j} \cdot \frac{\partial a^\ell_j}{\partial z^\ell_j} \\
&amp;= w_{kj} \sigma'(z^\ell_j).
\end{align*}</span></p>
<p>Finally, we can rewrite the error in layer <span class="math inline">\ell</span> as</p>
<p><span class="math display">
\delta^\ell_j = \sum_k \delta^{\ell+1}_k w_{kj} \sigma'(z^\ell_j).
</span></p>
<p>Once more, all the terms in the right hand side of the equation above are easy to compute, and we have the Inductive Step of our argument.</p>
</section>
<section id="summary" class="level2" data-number="56.5">
<h2 data-number="56.5" class="anchored" data-anchor-id="summary"><span class="header-section-number">56.5</span> summary</h2>
<p>We’ve learned the following. For each weight and bias <span class="math inline">j</span> in any layer <span class="math inline">\ell</span>, we can compute the error <span class="math inline">\delta^\ell_j</span> and update the parameters according to:</p>
<p><span class="math display">\begin{align*}
w_{jk}^\ell &amp;\leftarrow w_{jk}^\ell - \eta a^{\ell-1}_k \delta_j^\ell \\ \\
b_j^\ell &amp;\leftarrow b_j^\ell - \eta \delta_j^\ell.
\end{align*}</span></p>
<p>The backpropagation algorithm tells us to start from the last layer, compute the error there, and then work our way back to the first layer, computing the error in each layer and updating the parameters accordingly. The errors in the last layer are:</p>
<p><span class="math display">
\delta^L_j = \left[ \frac{1}{n}\sum_x \sum_k(y_k - a_k^L) \right] \cdot \sigma'(z^L_j),
</span></p>
<p>and the errors in the hidden layers are:</p>
<p><span class="math display">
\delta^\ell_j = \sum_k \delta^{\ell+1}_k w_{kj} \sigma'(z^\ell_j).
</span></p>
</section>
<section id="batches" class="level2" data-number="56.6">
<h2 data-number="56.6" class="anchored" data-anchor-id="batches"><span class="header-section-number">56.6</span> batches</h2>
<p>Instead of computing the cost and the errors for the entire dataset, we can do it for a small random sample of the data, called a batch. We just need to reinterpret the summation over <span class="math inline">x</span> in the equations above as a summation over the batch. This is what stochastic gradient descent is all about. It allows us to update the parameters more frequently, and it also adds some noise to the process, which makes our descent in the cost landscape less smooth, but can also help to escape local minima.</p>
<p>We start by shuffling our dataset, and then splitting it into batches. Then, for each batch, we perform:</p>
<ol type="1">
<li>the feedforward algorithm to compute the activations and weighted inputs for each layer, and finally the cost for the batch;</li>
<li>the backpropagation algorithm to compute the errors for each layer.</li>
<li>the update of the parameters according to the equations above.</li>
</ol>
<p>Once we’ve done this for all batches, we have completed one <strong>epoch</strong> of training. We can repeat this process for as many epochs as we want, until the cost is sufficiently low. We usually test the performance of our network on a separate test set, and track it as a function of the number of epochs.</p>
</section>
<section id="vectorizing-nielsens-backpropagation-code" class="level2" data-number="56.7">
<h2 data-number="56.7" class="anchored" data-anchor-id="vectorizing-nielsens-backpropagation-code"><span class="header-section-number">56.7</span> vectorizing Nielsen’s backpropagation code</h2>
<p>Nielsen mentions in the book that the code, as it is written, is not optimized. He proposes the following problem to solve:</p>
<blockquote class="blockquote">
<p>Fully matrix-based approach to backpropagation over a mini-batch Our implementation of stochastic gradient descent loops over training examples in a mini-batch. It’s possible to modify the backpropagation algorithm so that it computes the gradients for all training examples in a mini-batch simultaneously. The idea is that instead of beginning with a single input vector, x, we can begin with a matrix X=[x1x2…xm] whose columns are the vectors in the mini-batch. We forward-propagate by multiplying by the weight matrices, adding a suitable matrix for the bias terms, and applying the sigmoid function everywhere. We backpropagate along similar lines. Explicitly write out pseudocode for this approach to the backpropagation algorithm. Modify network.py so that it uses this fully matrix-based approach. The advantage of this approach is that it takes full advantage of modern libraries for linear algebra. As a result it can be quite a bit faster than looping over the mini-batch. (On my laptop, for example, the speedup is about a factor of two when run on MNIST classification problems like those we considered in the last chapter.) In practice, all serious libraries for backpropagation use this fully matrix-based approach or some variant.</p>
</blockquote>
<p>I’ll write below the actual code, not the pseudocode. I’ll then compare the performance of the vectorized code with the original code, and see if I can get a speedup of about a factor of two, as Nielsen claims.</p>
<p>Note: I’ve made a few updates to the original code in the book. In general, I wrote it to be more “modern” (I’m writing this in 2026). Also, I made sure I didn’t copy and paste anything, I’m typing it myself so I take ownership of this code. Here are the major modifications in this chapter:</p>
<ol type="1">
<li>I’ve added ReLU as the default activation function, but you can choose sigmoid if you want.</li>
<li>I added a progress bar to the training loop using <code>tqdm</code> to visualize the training progress.</li>
<li>You can quit training early by pressing <code>Ctrl+C</code>, the model will keep the weights without raising an error.</li>
<li>I’ve vectorized the backpropagation algorithm to handle batches efficiently, which should speed up training significantly.</li>
</ol>
<div id="40afa7a0" class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">class</span> NN:</span>
<span id="cb6-2"><a href="#cb6-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layer_sizes, rand_seed<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb6-3"><a href="#cb6-3"></a>        <span class="va">self</span>.number_of_layers <span class="op">=</span> <span class="bu">len</span>(layer_sizes)</span>
<span id="cb6-4"><a href="#cb6-4"></a>        <span class="va">self</span>.layer_sizes <span class="op">=</span> layer_sizes</span>
<span id="cb6-5"><a href="#cb6-5"></a>        <span class="co"># randomly initialize weights and biases</span></span>
<span id="cb6-6"><a href="#cb6-6"></a>        <span class="co"># input layer has no weights nor biases, so we skip it.</span></span>
<span id="cb6-7"><a href="#cb6-7"></a>        rng <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>rand_seed)</span>
<span id="cb6-8"><a href="#cb6-8"></a>        <span class="co"># each neuron get 1 bias, so bias vector has the size of the layer</span></span>
<span id="cb6-9"><a href="#cb6-9"></a>        <span class="va">self</span>.biases <span class="op">=</span> [rng.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>N_b)</span>
<span id="cb6-10"><a href="#cb6-10"></a>                       <span class="cf">for</span> N_b <span class="kw">in</span> layer_sizes[<span class="dv">1</span>:]]</span>
<span id="cb6-11"><a href="#cb6-11"></a>        <span class="co"># each neuron in layer Right is connected to all neurons in layer Left,</span></span>
<span id="cb6-12"><a href="#cb6-12"></a>        <span class="co"># so weight matrix has the shape (size_left, size_right)</span></span>
<span id="cb6-13"><a href="#cb6-13"></a>        <span class="va">self</span>.weights <span class="op">=</span> [rng.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>(size_left,size_right))</span>
<span id="cb6-14"><a href="#cb6-14"></a>                        <span class="cf">for</span> size_left, size_right <span class="kw">in</span></span>
<span id="cb6-15"><a href="#cb6-15"></a>                          <span class="bu">zip</span>(layer_sizes[:<span class="op">-</span><span class="dv">1</span>],layer_sizes[<span class="dv">1</span>:])</span>
<span id="cb6-16"><a href="#cb6-16"></a>                        ]</span>
<span id="cb6-17"><a href="#cb6-17"></a>    </span>
<span id="cb6-18"><a href="#cb6-18"></a>    <span class="kw">def</span> feedforward(<span class="va">self</span>, a):</span>
<span id="cb6-19"><a href="#cb6-19"></a>        <span class="co">"""given input `a` from the first layer,</span></span>
<span id="cb6-20"><a href="#cb6-20"></a><span class="co">           computes sequencially the activations of each layer</span></span>
<span id="cb6-21"><a href="#cb6-21"></a><span class="co">           finally returns the activations of last (output) layer</span></span>
<span id="cb6-22"><a href="#cb6-22"></a><span class="co">        """</span></span>
<span id="cb6-23"><a href="#cb6-23"></a>        <span class="cf">for</span> b, w <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.biases, <span class="va">self</span>.weights):</span>
<span id="cb6-24"><a href="#cb6-24"></a>            z <span class="op">=</span> np.dot(a, w) <span class="op">+</span> b</span>
<span id="cb6-25"><a href="#cb6-25"></a>            a <span class="op">=</span> activation_func(z)</span>
<span id="cb6-26"><a href="#cb6-26"></a>        <span class="cf">return</span> a</span>
<span id="cb6-27"><a href="#cb6-27"></a>    </span>
<span id="cb6-28"><a href="#cb6-28"></a>    <span class="kw">def</span> stochastic_gradient_descent(<span class="va">self</span>, training_data, epochs, batch_size, eta, test_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-29"><a href="#cb6-29"></a>        n <span class="op">=</span> <span class="bu">len</span>(training_data)</span>
<span id="cb6-30"><a href="#cb6-30"></a>        <span class="cf">for</span> epoch_j <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb6-31"><a href="#cb6-31"></a>            <span class="co"># shuffle training data at the beginning of each epoch</span></span>
<span id="cb6-32"><a href="#cb6-32"></a>            rng.shuffle(training_data)</span>
<span id="cb6-33"><a href="#cb6-33"></a>            <span class="co"># split training data into batches</span></span>
<span id="cb6-34"><a href="#cb6-34"></a>            batches <span class="op">=</span> [</span>
<span id="cb6-35"><a href="#cb6-35"></a>                training_data[k:k<span class="op">+</span>batch_size]</span>
<span id="cb6-36"><a href="#cb6-36"></a>                <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n, batch_size)</span>
<span id="cb6-37"><a href="#cb6-37"></a>            ]</span>
<span id="cb6-38"><a href="#cb6-38"></a>            <span class="co"># now loop over batches, update weights</span></span>
<span id="cb6-39"><a href="#cb6-39"></a>            <span class="cf">for</span> batch <span class="kw">in</span> batches:</span>
<span id="cb6-40"><a href="#cb6-40"></a>                <span class="va">self</span>.update_params_batch(batch, eta)</span>
<span id="cb6-41"><a href="#cb6-41"></a>            <span class="cf">if</span> test_data:</span>
<span id="cb6-42"><a href="#cb6-42"></a>                <span class="bu">print</span>(<span class="st">"Epoch </span><span class="sc">{epoch_j:02d}</span><span class="st">/</span><span class="sc">{epochs}</span><span class="st">: {self.evaluate(test_data)} / {len(test_data)}"</span>)</span>
<span id="cb6-43"><a href="#cb6-43"></a>            <span class="cf">else</span>:</span>
<span id="cb6-44"><a href="#cb6-44"></a>                <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch_j<span class="sc">:02d}</span><span class="ss"> complete"</span>)</span>
<span id="cb6-45"><a href="#cb6-45"></a>    </span>
<span id="cb6-46"><a href="#cb6-46"></a>    <span class="kw">def</span> update_params_batch(<span class="va">self</span>, batch, eta):</span>
<span id="cb6-47"><a href="#cb6-47"></a>        <span class="co"># 1. make input matrix, use row-major order, so each row is a training example, and each column is a feature.</span></span>
<span id="cb6-48"><a href="#cb6-48"></a>        <span class="bu">input</span> <span class="op">=</span> np.array([data[<span class="dv">0</span>] <span class="cf">for</span> data <span class="kw">in</span> batch])</span>
<span id="cb6-49"><a href="#cb6-49"></a>        <span class="co"># 2. make label matrix, use row-major order, so each row is a training example, and each column is a label.</span></span>
<span id="cb6-50"><a href="#cb6-50"></a>        target <span class="op">=</span> np.array([data[<span class="dv">1</span>] <span class="cf">for</span> data <span class="kw">in</span> batch])</span>
<span id="cb6-51"><a href="#cb6-51"></a>        <span class="co"># 3. compute the gradients for the whole batch using back propagation</span></span>
<span id="cb6-52"><a href="#cb6-52"></a>        nabla_b, nabla_w <span class="op">=</span> <span class="va">self</span>.back_propagation(<span class="bu">input</span>, target)</span>
<span id="cb6-53"><a href="#cb6-53"></a>        <span class="co"># update biases and weights</span></span>
<span id="cb6-54"><a href="#cb6-54"></a>        m <span class="op">=</span> <span class="bu">len</span>(batch)</span>
<span id="cb6-55"><a href="#cb6-55"></a>        <span class="va">self</span>.biases <span class="op">=</span> [</span>
<span id="cb6-56"><a href="#cb6-56"></a>            b <span class="op">-</span> (eta<span class="op">/</span>m) <span class="op">*</span> nb</span>
<span id="cb6-57"><a href="#cb6-57"></a>            <span class="cf">for</span> b, nb <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.biases, nabla_b)</span>
<span id="cb6-58"><a href="#cb6-58"></a>        ]</span>
<span id="cb6-59"><a href="#cb6-59"></a>        <span class="va">self</span>.weights <span class="op">=</span> [</span>
<span id="cb6-60"><a href="#cb6-60"></a>            w <span class="op">-</span> (eta<span class="op">/</span>m) <span class="op">*</span> nw</span>
<span id="cb6-61"><a href="#cb6-61"></a>            <span class="cf">for</span> w, nw <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.weights, nabla_w)</span>
<span id="cb6-62"><a href="#cb6-62"></a>        ]</span>
<span id="cb6-63"><a href="#cb6-63"></a>    </span>
<span id="cb6-64"><a href="#cb6-64"></a>    <span class="kw">def</span> back_propagation(<span class="va">self</span>, <span class="bu">input</span>, target):</span>
<span id="cb6-65"><a href="#cb6-65"></a>        <span class="co"># 1. forward pass</span></span>
<span id="cb6-66"><a href="#cb6-66"></a>        <span class="co"># 1a. create variables to store the activations and z vectors for each layer, starting with the input layer</span></span>
<span id="cb6-67"><a href="#cb6-67"></a>        activation <span class="op">=</span> <span class="bu">input</span></span>
<span id="cb6-68"><a href="#cb6-68"></a>        activation_list <span class="op">=</span> [<span class="bu">input</span>]  <span class="co"># initialize with input layer activations</span></span>
<span id="cb6-69"><a href="#cb6-69"></a>        z_list <span class="op">=</span> []</span>
<span id="cb6-70"><a href="#cb6-70"></a>        <span class="co"># 1b. loop over layers in forward direction,</span></span>
<span id="cb6-71"><a href="#cb6-71"></a>        <span class="co"># compute and store the activations and z vectors layer by layer</span></span>
<span id="cb6-72"><a href="#cb6-72"></a>        <span class="co"># for the whole batch at once.</span></span>
<span id="cb6-73"><a href="#cb6-73"></a>        <span class="cf">for</span> b, w <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.biases, <span class="va">self</span>.weights):</span>
<span id="cb6-74"><a href="#cb6-74"></a>            z <span class="op">=</span> np.dot(activation, w) <span class="op">+</span> b</span>
<span id="cb6-75"><a href="#cb6-75"></a>            activation <span class="op">=</span> activation_func(z)</span>
<span id="cb6-76"><a href="#cb6-76"></a>            z_list.append(z)</span>
<span id="cb6-77"><a href="#cb6-77"></a>            activation_list.append(activation)</span>
<span id="cb6-78"><a href="#cb6-78"></a>        <span class="co">#####</span></span>
<span id="cb6-79"><a href="#cb6-79"></a>        <span class="co"># now we have all the information we need to compute the gradients in the backward pass.</span></span>
<span id="cb6-80"><a href="#cb6-80"></a>        <span class="co">#####</span></span>
<span id="cb6-81"><a href="#cb6-81"></a>        <span class="co"># 2. backward pass</span></span>
<span id="cb6-82"><a href="#cb6-82"></a>        <span class="co"># 2a. create empty lists to store the gradients for biases and weights, layer by layer</span></span>
<span id="cb6-83"><a href="#cb6-83"></a>        nabla_b <span class="op">=</span> [np.zeros_like(b) <span class="cf">for</span> b <span class="kw">in</span> <span class="va">self</span>.biases]</span>
<span id="cb6-84"><a href="#cb6-84"></a>        nabla_w <span class="op">=</span> [np.zeros_like(w) <span class="cf">for</span> w <span class="kw">in</span> <span class="va">self</span>.weights]</span>
<span id="cb6-85"><a href="#cb6-85"></a>        <span class="co"># 2b. first compute the error "delta" for the output layer</span></span>
<span id="cb6-86"><a href="#cb6-86"></a>        <span class="co"># this is what we called the "base case"</span></span>
<span id="cb6-87"><a href="#cb6-87"></a>        delta <span class="op">=</span> <span class="va">self</span>.cost_derivative(activation_list[<span class="op">-</span><span class="dv">1</span>], target) <span class="op">*</span> activation_func_derivative(z_list[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb6-88"><a href="#cb6-88"></a>        <span class="co"># 2c. compute and store the gradients for the output layer</span></span>
<span id="cb6-89"><a href="#cb6-89"></a>        nabla_b[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> delta</span>
<span id="cb6-90"><a href="#cb6-90"></a>        nabla_w[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> np.dot(activation_list[<span class="op">-</span><span class="dv">2</span>].T, delta)</span>
<span id="cb6-91"><a href="#cb6-91"></a>        <span class="co"># 2c. loop over layers in reverse order,</span></span>
<span id="cb6-92"><a href="#cb6-92"></a>        <span class="co"># compute the gradients for each layer. This is the "inductive step".</span></span>
<span id="cb6-93"><a href="#cb6-93"></a>        <span class="co"># the loop starts at the second to last layer, and goes backwards to the first hidden layer.</span></span>
<span id="cb6-94"><a href="#cb6-94"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="va">self</span>.number_of_layers):</span>
<span id="cb6-95"><a href="#cb6-95"></a>            z <span class="op">=</span> z_list[<span class="op">-</span>l]</span>
<span id="cb6-96"><a href="#cb6-96"></a>            <span class="co"># the transpose is needed because we want to compute the dot product</span></span>
<span id="cb6-97"><a href="#cb6-97"></a>            <span class="co"># of the error from the next layer with the weights,</span></span>
<span id="cb6-98"><a href="#cb6-98"></a>            <span class="co"># and the weights are stored in a way that the input layer is the first dimension,</span></span>
<span id="cb6-99"><a href="#cb6-99"></a>            <span class="co"># and the output layer is the second dimension.</span></span>
<span id="cb6-100"><a href="#cb6-100"></a>            delta <span class="op">=</span> np.dot(delta, <span class="va">self</span>.weights[<span class="op">-</span>l<span class="op">+</span><span class="dv">1</span>].T) <span class="op">*</span> activation_func_derivative(z)</span>
<span id="cb6-101"><a href="#cb6-101"></a>            nabla_b[<span class="op">-</span>l] <span class="op">=</span> delta</span>
<span id="cb6-102"><a href="#cb6-102"></a>            nabla_w[<span class="op">-</span>l] <span class="op">=</span> np.dot(activation_list[<span class="op">-</span>l<span class="op">-</span><span class="dv">1</span>].T, delta)</span>
<span id="cb6-103"><a href="#cb6-103"></a>        <span class="cf">return</span> nabla_b, nabla_w</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../neural_networks/nielsen_ch1.html" class="pagination-link" aria-label="Nielsen's NNDL, ch.1">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.1</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../misc/trend_test.html" class="pagination-link" aria-label="trend test">
        <span class="nav-page-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">trend test</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>