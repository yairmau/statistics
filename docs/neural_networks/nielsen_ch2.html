<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>56&nbsp; Nielsen’s NNDL, ch.2 – Statistics and Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../misc/trend_test.html" rel="next">
<link href="../neural_networks/nielsen_ch1.html" rel="prev">
<link href="../archive/logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-a588049bcf6ba0aff1d03aeee07a0105.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-2c63ad6a8cffefe8536d13eabcc001d1.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TB8VQN4T5W"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-TB8VQN4T5W', { 'anonymize_ip': true});
</script>
<!-- <link href="//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css" rel="stylesheet">
<script src="https://code.iconify.design/1/1.0.7/iconify.min.js"></script>
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.10.2/css/all.css"> -->

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../neural_networks/nielsen_ch1.html">neural networks</a></li><li class="breadcrumb-item"><a href="../neural_networks/nielsen_ch2.html"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.2</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../archive/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Statistics and Machine Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://yairmau.com/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-house-fill"></i></a>
    <a href="https://github.com/yairmau/statistics/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/height.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">height data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/weight.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">weight data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">hypothesis testing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/t_test_one_sample.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">one-sample t-test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/t_test_independent_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">independent samples t-test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/statistical_power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">statistical power</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/problem-with-t-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">the problem with t-test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/permutation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">permutation test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/numpy-vs-pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">numpy vs pandas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../hypothesis_testing/exact-vs-montecarlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">exact vs.&nbsp;Monte Carlo permutation tests</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">confidence interval</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../confidence_interval/basic_concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">basic concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../confidence_interval/analytical_confidence_interval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">analytical confidence interval</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../confidence_interval/empirical_confidence_interval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">empirical confidence interval</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/geometry-of-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">the geometry of regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/least-squares.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">least squares</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/partitioning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">partitioning of the sum of squares</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/R-squared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">R-squared</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/equivalence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">equivalence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/mixed-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">linear mixed effect model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">logistic regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/logistic_2d.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">logistic 2d</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">correlation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correlation/correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">correlation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correlation/linear_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">correlation and linear regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correlation/cosine.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">cosine</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correlation/significance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">significance (p-value)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">bayes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/from-the-ground-up.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Bayes’ theorem from the ground up</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/parametric-generative-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">parametric generative classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/odds.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">odds and log likelihood</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/logistic-connection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">logistic connection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/conjugate-prior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">conjugate prior</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/boy-girl-paradox.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">the boy-girl paradox</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../bayes/monty-hall.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">monty hall</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">svd and pca</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../svd_and_pca/svd_image_compression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">SVD for image compression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../svd_and_pca/svd_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">SVD for regression</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">decision trees</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../decision_trees/CART_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">CART: classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../decision_trees/CART_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">CART: regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../decision_trees/random_forest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">random forest</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">information theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../information_theory/entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">entropy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../information_theory/cross-entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">cross-entropy and KL divergence</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">likelihood</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/probability_and_likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">probability and likelihood</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">maximum likelihood estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_summary_statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">MLE and summary statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_linear_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">MLE and linear regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_information_theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">MLE and information theory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">MLE and regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">MLE and classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../likelihood/MLE_and_bayesian_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">MLE and bayesian inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">generalization and model complexity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/motivation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">motivation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">bias-variance tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/overfitting-and-underfitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">overfitting and underfitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/cross-validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">cross-validation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/data-splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">data splitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">regularization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/more-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">when more data changes the tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../generalization/double-descent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">double descent</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">neural networks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../neural_networks/nielsen_ch1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../neural_networks/nielsen_ch2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.2</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">miscellaneous</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../misc/trend_test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">trend test</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../misc/shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">SHAP values</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#derivation" id="toc-derivation" class="nav-link active" data-scroll-target="#derivation"><span class="header-section-number">56.1</span> derivation</a>
  <ul class="collapse">
  <li><a href="#cost" id="toc-cost" class="nav-link" data-scroll-target="#cost"><span class="header-section-number">56.1.1</span> cost</a></li>
  <li><a href="#rule-for-updating-the-parameters" id="toc-rule-for-updating-the-parameters" class="nav-link" data-scroll-target="#rule-for-updating-the-parameters"><span class="header-section-number">56.1.2</span> rule for updating the parameters</a></li>
  <li><a href="#the-structure-of-the-argument" id="toc-the-structure-of-the-argument" class="nav-link" data-scroll-target="#the-structure-of-the-argument"><span class="header-section-number">56.1.3</span> the structure of the argument</a></li>
  </ul></li>
  <li><a href="#the-error" id="toc-the-error" class="nav-link" data-scroll-target="#the-error"><span class="header-section-number">56.2</span> the “error”</a></li>
  <li><a href="#base-case-the-output-layer" id="toc-base-case-the-output-layer" class="nav-link" data-scroll-target="#base-case-the-output-layer"><span class="header-section-number">56.3</span> base case: the output layer</a></li>
  <li><a href="#the-inductive-step-the-hidden-layers" id="toc-the-inductive-step-the-hidden-layers" class="nav-link" data-scroll-target="#the-inductive-step-the-hidden-layers"><span class="header-section-number">56.4</span> the inductive step: the hidden layers</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">56.5</span> summary</a></li>
  <li><a href="#batches" id="toc-batches" class="nav-link" data-scroll-target="#batches"><span class="header-section-number">56.6</span> batches</a></li>
  <li><a href="#vectorizing-nielsens-backpropagation-code" id="toc-vectorizing-nielsens-backpropagation-code" class="nav-link" data-scroll-target="#vectorizing-nielsens-backpropagation-code"><span class="header-section-number">56.7</span> vectorizing Nielsen’s backpropagation code</a></li>
  <li><a href="#widget" id="toc-widget" class="nav-link" data-scroll-target="#widget"><span class="header-section-number">56.8</span> widget</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../neural_networks/nielsen_ch1.html">neural networks</a></li><li class="breadcrumb-item"><a href="../neural_networks/nielsen_ch2.html"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.2</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.2</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button" data-quarto-source-url="https://github.com/yairmau/statistics/blob/main/neural_networks/nielsen_ch2.ipynb">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>I’m not sure I have something new to add to the vast number of explanations on backpropagation found on the internet. Almost certainly I don’t. However, I can only truly grasp a concept if I work it out myself, and that’s what this chapter is about. I found <a href="https://www.youtube.com/watch?v=VMj-3S1tku0">Andrej Karpathy’s youtube video</a> on micrograd very useful. He really takes the time to explain the mechanics behind backpropagation. Another useful source was <a href="https://youtu.be/Ilg3gGewQ5U?si=4q294k85uvQfBucz">3b1b youtube videos</a>. It’s obvious that he’s restating Nielsen’s arguments, but with greater pedagogical clarity and superb visualizations. With regard to Nielsen’s approach, I personally hated that he first showed the end form of the equations, and only at the very end of the chapter went about deriving them. At the outset, he says about the first equation “This is a very natural expression”. Personally I found nothing natural until I fully understood the derivation. Also, the order of the equations is wrong: what we really need are equations 3 and 4, and equations 1 and 2 are the means to calculate what we need. Nielsen, if you’re reading this, know that this criticism comes from a place of love, you did a great service to humanity. I’ll stop ranting now, and I’ll derive backpropagation myself. If you don’t quite get it, it’s probably because I’m writing to someone who I assumed to have read Nielsen’s book (which you should).</p>
<section id="derivation" class="level2" data-number="56.1">
<h2 data-number="56.1" class="anchored" data-anchor-id="derivation"><span class="header-section-number">56.1</span> derivation</h2>
<section id="cost" class="level3" data-number="56.1.1">
<h3 data-number="56.1.1" class="anchored" data-anchor-id="cost"><span class="header-section-number">56.1.1</span> cost</h3>
<p>We start with the cost function. For one given input <span class="math inline">x</span> (one photo of a digit in our dataset), we run our neural network with the usual feed forward algorithm, and get the vector of activations <span class="math inline">a</span> at the last layer <span class="math inline">L</span>. The cost then will be</p>
<p><span class="math display">
C_x = \frac{1}{2} \sum_j \left( y_j - a^L_j\right)^2.
</span></p>
<p>The one half has no special significance here, it will just make life a bit easier in the future, once we take the derivative of the cost. But let’s not get distracted.</p>
<p>We sum over <span class="math inline">j</span>, the index counting the number of neurons in the output layer, which in our case is 10. <span class="math inline">y_j</span> represents the one-hot label of the digit in <span class="math inline">x</span>. For instance, for the digit <span class="math inline">3</span> we might get something like that:</p>
<p><span class="math display">
y =
\begin{bmatrix}
0\\0\\0\\1\\0\\0\\0\\0\\0\\0
\end{bmatrix},
\quad
a^L =
\begin{bmatrix}
0.1\\0.7\\0.0\\0.5\\0.4\\0.6\\0.1\\0.0\\0.1\\0.6
\end{bmatrix},
\quad
(y-a^L)^2 =
\begin{bmatrix}
0.01\\0.49\\0.0\\0.25\\0.16\\0.36\\0.01\\0.0\\0.01\\0.36
\end{bmatrix}.
</span></p>
<p>Then <span class="math inline">C_x</span> is just half of the sum of this last vector. So far so good. But what about all the other thousands of input images? We do the same for them, and get the total cost for our entire dataset:</p>
<p><span class="math display">
C = \frac{1}{n}\sum_x C_x
</span></p>
</section>
<section id="rule-for-updating-the-parameters" class="level3" data-number="56.1.2">
<h3 data-number="56.1.2" class="anchored" data-anchor-id="rule-for-updating-the-parameters"><span class="header-section-number">56.1.2</span> rule for updating the parameters</h3>
<p>Our goal is to update each and every weight and bias in our neural network, so to decrease as much as we can this cost. The lower the cost, the more accurate will be our number classification.</p>
<p>This cost lives in a multi-dimensional space. By the gradient descent method, we take a tiny step in the parameter space in the direction opposite to the gradient of the cost. If <span class="math inline">p</span> is to represent our parameter vector, than we would write</p>
<p><span class="math display">
p_\text{new} = p_\text{old} - \eta \nabla C,
</span></p>
<p>where <span class="math inline">\eta</span> is the learning rate.</p>
<p>Each element of <span class="math inline">p</span> is a weight or bias in the network. Now is the right time to be precise and refer specifically to each parameter, and first we need a good mental model for the parameters. The quantities <span class="math inline">b</span>, <span class="math inline">z</span>, and <span class="math inline">a</span> are easy to understand, each “belongs” to a specific neuron <span class="math inline">j</span> in a specific layer <span class="math inline">\ell</span>, therefore we index them as <span class="math inline">b^\ell_j</span>, <span class="math inline">z^\ell_j</span>, and <span class="math inline">a^\ell_j</span>. One thing we should be aware of is that the activation exists for the input layer as well, and we can denote it as <span class="math inline">a^{-1}_j</span>, since I chose to index the first hidden layer as zero. Another thing is that I chose to start all the indices from zero (as is done in Python), but we could have started from one as well. The choice is arbitrary, and I it doesn’t matter which one we choose, as long as we’re consistent.</p>
<p>The weights are a bit more complicated, because they connect two neurons from neighboring layers. The easiest way to think about them is to say that a given weight belongs to a neuron <span class="math inline">j</span> in layer <span class="math inline">\ell</span>, and it connects this neuron to a neuron <span class="math inline">k</span> in the previous layer <span class="math inline">\ell-1</span>. Therefore we can index them as <span class="math inline">w^\ell_{jk}</span>. This interpretation makes it intuitive to remember the order of the lower indices: the first one is the layer of the neuron to which the weight belongs, and the second one is the index of the neuron it connects to in the previous layer.</p>
<p>Lastly, the equation for computing the weighted input <span class="math inline">z^\ell_j</span> of a neuron <span class="math inline">j</span> in layer <span class="math inline">\ell</span> becomes obvious once we connect it to the figure below.</p>
<p><span class="math display">
z^\ell_j = \sum_k w^\ell_{jk} a^{\ell-1}_k + b^\ell_j.
</span></p>
<div id="898770e0" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>import libraries</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> io</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> gzip</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> requests</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> patches</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="im">import</span> json</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">import</span> time</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="818c90ce" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>plot NN</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb2-2"><a href="#cb2-2"></a>layer_left <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>layer_center <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>layer_right <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>layer_right2 <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a>layers <span class="op">=</span> [layer_left, layer_center, layer_right, layer_right2]</span>
<span id="cb2-8"><a href="#cb2-8"></a></span>
<span id="cb2-9"><a href="#cb2-9"></a>weights <span class="op">=</span> []</span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="cf">for</span> l, layer <span class="kw">in</span> <span class="bu">enumerate</span>(layers[:<span class="op">-</span><span class="dv">1</span>]):</span>
<span id="cb2-11"><a href="#cb2-11"></a>    weights.append(np.ones((layers[l<span class="op">+</span><span class="dv">1</span>], layer)))</span>
<span id="cb2-12"><a href="#cb2-12"></a></span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="cf">for</span> l,w <span class="kw">in</span> <span class="bu">enumerate</span>(weights):</span>
<span id="cb2-14"><a href="#cb2-14"></a>    x_left <span class="op">=</span> l</span>
<span id="cb2-15"><a href="#cb2-15"></a>    x_right <span class="op">=</span> l<span class="op">+</span><span class="dv">1</span><span class="op">-</span><span class="fl">0.2</span></span>
<span id="cb2-16"><a href="#cb2-16"></a>    x_b <span class="op">=</span> l<span class="op">+</span><span class="dv">1</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>    <span class="cf">for</span> index, value <span class="kw">in</span> np.ndenumerate(w):</span>
<span id="cb2-18"><a href="#cb2-18"></a>        y_right <span class="op">=</span> index[<span class="dv">0</span>] <span class="op">-</span> layers[l<span class="op">+</span><span class="dv">1</span>]<span class="op">/</span><span class="dv">2</span></span>
<span id="cb2-19"><a href="#cb2-19"></a>        y_left <span class="op">=</span> index[<span class="dv">1</span>] <span class="op">-</span> layers[l]<span class="op">/</span><span class="dv">2</span></span>
<span id="cb2-20"><a href="#cb2-20"></a>        zorder <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb2-21"><a href="#cb2-21"></a>        <span class="cf">if</span> (l<span class="op">==</span><span class="dv">0</span> <span class="kw">and</span> index[<span class="dv">0</span>]<span class="op">==</span><span class="dv">4</span>):</span>
<span id="cb2-22"><a href="#cb2-22"></a>            color <span class="op">=</span> <span class="st">"xkcd:cerulean"</span></span>
<span id="cb2-23"><a href="#cb2-23"></a>        <span class="cf">elif</span> (l<span class="op">==</span><span class="dv">1</span> <span class="kw">and</span> index[<span class="dv">0</span>]<span class="op">==</span><span class="dv">0</span>):</span>
<span id="cb2-24"><a href="#cb2-24"></a>            color <span class="op">=</span> <span class="st">"xkcd:vermillion"</span></span>
<span id="cb2-25"><a href="#cb2-25"></a>        <span class="cf">elif</span> (l<span class="op">==</span><span class="dv">2</span> <span class="kw">and</span> index[<span class="dv">0</span>]<span class="op">==</span>layers[l<span class="op">+</span><span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb2-26"><a href="#cb2-26"></a>            color <span class="op">=</span> <span class="st">"xkcd:barney"</span></span>
<span id="cb2-27"><a href="#cb2-27"></a>            </span>
<span id="cb2-28"><a href="#cb2-28"></a>        <span class="cf">else</span>: color <span class="op">=</span> [<span class="fl">0.8</span>]<span class="op">*</span><span class="dv">3</span><span class="op">;</span> zorder <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-29"><a href="#cb2-29"></a>        ax.plot([x_left, x_right], [y_left, y_right], color<span class="op">=</span>color, zorder<span class="op">=</span>zorder)</span>
<span id="cb2-30"><a href="#cb2-30"></a>        ax.plot([x_b, x_right], [y_right, y_right], color<span class="op">=</span>color, zorder<span class="op">=</span>zorder)</span>
<span id="cb2-31"><a href="#cb2-31"></a></span>
<span id="cb2-32"><a href="#cb2-32"></a>ax.text(<span class="dv">3</span><span class="op">-</span><span class="fl">0.15</span>, np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span> <span class="op">+</span><span class="fl">0.1</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">b_</span><span class="ch">{{</span><span class="op">0</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">2</span><span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span>color, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-33"><a href="#cb2-33"></a>ax.text(<span class="dv">3</span><span class="op">-</span><span class="fl">0.5</span>, np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span> <span class="op">-</span> <span class="fl">0.2</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">w_</span><span class="ch">{{</span><span class="vs">0j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">2</span><span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span>color, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-34"><a href="#cb2-34"></a>ax.text(<span class="dv">3</span><span class="op">+</span><span class="fl">0.6</span>, np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span> <span class="op">-</span> <span class="fl">1.3</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">z_</span><span class="ch">{{</span><span class="op">0</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">2</span><span class="sc">}</span><span class="vs"> = </span><span class="dv">\s</span><span class="vs">um_j w_</span><span class="ch">{{</span><span class="vs">0j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="sc">}</span><span class="er">\</span><span class="vs">cdot </span><span class="er">\</span><span class="vs">quad </span><span class="op">+</span><span class="vs"> b_</span><span class="ch">{{</span><span class="op">0</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span>l<span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span>color, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-35"><a href="#cb2-35"></a></span>
<span id="cb2-36"><a href="#cb2-36"></a>ms <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb2-37"><a href="#cb2-37"></a>neuron_colors <span class="op">=</span> [<span class="st">'white'</span>, <span class="st">'xkcd:cerulean'</span>, <span class="st">'xkcd:vermillion'</span>, <span class="st">'xkcd:barney'</span>]</span>
<span id="cb2-38"><a href="#cb2-38"></a>text_colors <span class="op">=</span> [<span class="st">'gray'</span>, <span class="st">'white'</span>, <span class="st">'white'</span>, <span class="st">'white'</span>]</span>
<span id="cb2-39"><a href="#cb2-39"></a><span class="cf">for</span> l, layer <span class="kw">in</span> <span class="bu">enumerate</span>(layers):</span>
<span id="cb2-40"><a href="#cb2-40"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer):</span>
<span id="cb2-41"><a href="#cb2-41"></a>        ax.plot([l], [i <span class="op">-</span> layer<span class="op">/</span><span class="dv">2</span>], ls<span class="op">=</span><span class="st">'None'</span>, marker<span class="op">=</span><span class="st">'o'</span>, mfc<span class="op">=</span>neuron_colors[l], mec<span class="op">=</span><span class="st">"black"</span>, markersize<span class="op">=</span>ms,</span>
<span id="cb2-42"><a href="#cb2-42"></a>                color<span class="op">=</span>neuron_colors[l], lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">1.0</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-43"><a href="#cb2-43"></a>        ax.text(l, i <span class="op">-</span> layer<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.05</span>, <span class="ss">f"</span><span class="sc">{</span>layer<span class="op">-</span>i<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">10</span>, color<span class="op">=</span>text_colors[l], zorder<span class="op">=</span><span class="dv">1000</span>)   </span>
<span id="cb2-44"><a href="#cb2-44"></a></span>
<span id="cb2-45"><a href="#cb2-45"></a>ax.text(<span class="dv">0</span>, <span class="op">-</span>np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="ss">f"input layer"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"gray"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-46"><a href="#cb2-46"></a>ax.text(<span class="dv">1</span>, <span class="op">-</span>np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="ss">f"layer 0"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:cerulean"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-47"><a href="#cb2-47"></a>ax.text(<span class="dv">2</span>, <span class="op">-</span>np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="ss">f"layer 1"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:vermillion"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-48"><a href="#cb2-48"></a>ax.text(<span class="dv">3</span>, <span class="op">-</span>np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="ss">f"layer 2</span><span class="ch">\n</span><span class="ss">(output)"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:barney"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-49"><a href="#cb2-49"></a></span>
<span id="cb2-50"><a href="#cb2-50"></a>ax.text(<span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="op">-</span><span class="fl">2.6</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">w_</span><span class="ch">{{</span><span class="vs">3j</span><span class="ch">}}</span><span class="dv">^</span><span class="vs">1</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:vermillion"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-51"><a href="#cb2-51"></a>ax.text(<span class="dv">2</span><span class="op">-</span><span class="fl">0.15</span>, <span class="op">-</span><span class="fl">2.2</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">b_</span><span class="ch">{{</span><span class="op">3</span><span class="ch">}}</span><span class="dv">^</span><span class="vs">1</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"top"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:vermillion"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-52"><a href="#cb2-52"></a>ax.text(<span class="dv">2</span>, (layers[<span class="dv">2</span>])<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">z_</span><span class="ch">{{</span><span class="vs">j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">1</span><span class="sc">}</span><span class="vs">,a_</span><span class="ch">{{</span><span class="vs">j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">1</span><span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:vermillion"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-53"><a href="#cb2-53"></a>ax.text(<span class="dv">3</span><span class="op">+</span><span class="fl">0.6</span><span class="op">+</span><span class="fl">0.17</span>, np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span> <span class="op">-</span> <span class="fl">1.2</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">a_</span><span class="ch">{{</span><span class="vs">j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">1</span><span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:vermillion"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-54"><a href="#cb2-54"></a>ax.text(<span class="fl">3.1</span>, np.<span class="bu">max</span>(layers)<span class="op">/</span><span class="dv">2</span> <span class="op">-</span> <span class="fl">1.9</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">a_</span><span class="ch">{{</span><span class="op">0</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">2</span><span class="sc">}</span><span class="vs">=</span><span class="dv">\s</span><span class="vs">igma</span><span class="kw">(</span><span class="vs">z_</span><span class="ch">{{</span><span class="op">0</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">2</span><span class="sc">}</span><span class="kw">)</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"left"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:barney"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-55"><a href="#cb2-55"></a>ax.text(<span class="dv">1</span>, (layers[<span class="dv">1</span>])<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">z_</span><span class="ch">{{</span><span class="vs">j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">0</span><span class="sc">}</span><span class="vs">,a_</span><span class="ch">{{</span><span class="vs">j</span><span class="ch">}}</span><span class="dv">^</span><span class="sc">{</span><span class="dv">0</span><span class="sc">}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"xkcd:cerulean"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-56"><a href="#cb2-56"></a>ax.text(<span class="dv">0</span>, (layers[<span class="dv">0</span>])<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="fl">0.5</span>, <span class="vs">fr"</span><span class="dv">$</span><span class="vs">a_</span><span class="ch">{{</span><span class="vs">j</span><span class="ch">}}</span><span class="dv">^</span><span class="ch">{{</span><span class="vs">-1</span><span class="ch">}}</span><span class="dv">$</span><span class="vs">"</span>, ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"gray"</span>, zorder<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb2-57"><a href="#cb2-57"></a>ax.<span class="bu">set</span>(xlim<span class="op">=</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="dv">4</span>), ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">4</span>), xticks<span class="op">=</span>[], yticks<span class="op">=</span>[])</span>
<span id="cb2-58"><a href="#cb2-58"></a><span class="co"># ax.set_aspect('equal')</span></span>
<span id="cb2-59"><a href="#cb2-59"></a>ax.axis(<span class="st">'off'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="nielsen_ch2_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In the figure above, I color coded <span class="math inline">z</span>, <span class="math inline">a</span>, <span class="math inline">w</span> and <span class="math inline">b</span> by color, each color corresponding to a specific layer.</p>
<p>Translating the general parameter in the equation above to weights and biases gives the following update rules:</p>
<p><span class="math display">\begin{align*}
w_{jk}^\ell &amp;\leftarrow w_{jk}^{\ell} - \eta \frac{\partial C}{\partial w_{jk}^{\ell}} \\ \\
b_j^\ell &amp;\leftarrow b_j^{\ell} - \eta \frac{\partial C}{\partial b_j^{\ell}}.
\end{align*}</span></p>
</section>
<section id="the-structure-of-the-argument" class="level3" data-number="56.1.3">
<h3 data-number="56.1.3" class="anchored" data-anchor-id="the-structure-of-the-argument"><span class="header-section-number">56.1.3</span> the structure of the argument</h3>
<p>The backpropagation algorithm is at its essence an induction.</p>
<ol type="1">
<li>We can find out the partial derivatives for the very last layer, the output layer. This is the Base Case.</li>
<li>We can show that given the partial derivatives in any given layer <span class="math inline">\ell</span>, we can figure out what the partial derivatives are in the layer that precedes it, <span class="math inline">\ell-1</span>. This is the Inductive Step.</li>
<li>That’s it. Starting from the last layer, we can work our way out to the first layer. That explains the name of the algorithm, we’re backpropagating the information, from last to first.</li>
</ol>
</section>
</section>
<section id="the-error" class="level2" data-number="56.2">
<h2 data-number="56.2" class="anchored" data-anchor-id="the-error"><span class="header-section-number">56.2</span> the “error”</h2>
<p>For a given weight or bias, let’s use the chain rule to begin unfolding the partial derivatives we need to find out. It’s best to rewrite an equation we saw before, to make the derivatives easier to understand: <span class="math inline">z^\ell_j = \sum_k w^\ell_{jk} a^{\ell-1}_k + b^\ell_j</span>.</p>
<p><span class="math display">\begin{align*}
\frac{\partial C}{\partial w^\ell_{jk}} &amp;= \left( \frac{\partial C}{\partial z^\ell_j} \right) \frac{\partial z^\ell_j}{\partial w^\ell_{jk}} = \left( \frac{\partial C}{\partial z^\ell_j} \right) a^{\ell-1}_k  \\ \\
\frac{\partial C}{\partial b^\ell_j} &amp;= \left(\frac{\partial C}{\partial z^\ell_j}\right) \frac{\partial z^\ell_j}{\partial b^\ell_j} = \left( \frac{\partial C}{\partial z^\ell_j} \right).
\end{align*}</span></p>
<p>This is great, now both terms look almost the same! We found that we need to calculate the quantity in the parentheses, which we will call the <strong>error</strong>:</p>
<p><span class="math display">
\delta^\ell_j =\frac{\partial C}{\partial z^\ell_j}
</span></p>
<p>The equation above asks: how sensitive is the total cost <span class="math inline">C</span> to tiny variations in a specific weighted input <span class="math inline">z</span> at the <span class="math inline">j</span>th neuron in layer <span class="math inline">\ell</span>.</p>
<p>Let’s compute this error for the last layer <span class="math inline">L</span>, and lay out the Base Case of our induction.</p>
</section>
<section id="base-case-the-output-layer" class="level2" data-number="56.3">
<h2 data-number="56.3" class="anchored" data-anchor-id="base-case-the-output-layer"><span class="header-section-number">56.3</span> base case: the output layer</h2>
<p>The last layer has index <span class="math inline">L</span>, and the error for the <span class="math inline">j</span>th neuron in this layer is <span class="math display">
\delta^L_j = \frac{\partial C}{\partial z^L_j}.
</span></p>
<p>Let’s use the chain rule to unfold this derivative:</p>
<p><span class="math display">
\delta^L_j = \frac{\partial C}{\partial a^L_j} \frac{\partial a^L_j}{\partial z^L_j}.
</span></p>
<p>Remember that the activation <span class="math inline">a</span> is simply</p>
<p><span class="math display">
a = \sigma(z),
</span></p>
<p>so we have that <span class="math inline">\partial a/\partial z=\sigma'(z)</span>. Rewriting the error gives</p>
<p><span class="math display">
\delta^L_j = \frac{\partial C}{\partial a^L_j} \cdot \sigma'(z^L_j).
</span></p>
<p>We’re in luck, because each of the two terms in the right hand side of the equation above is easy to calculate. The first term is</p>
<p><span class="math display">\begin{align*}
\frac{\partial C}{\partial a^L_j} &amp;= \frac{\partial}{\partial a^L_j} \left[ \frac{1}{n}\sum_x \frac{1}{2} \sum_j \left( y_j - a^L_j\right)^2 \right] \\
&amp;=
\frac{1}{n}\sum_x \sum_j \left( y_j - a^L_j\right).
\end{align*}</span></p>
<p>Let’s translate that into words: the first term is simply the difference <span class="math inline">\left( y_j - a^L_j\right)</span>, summed over all neurons <span class="math inline">j</span> in the output layer, and averaged over all input images <span class="math inline">x</span>. That’s super easy to compute! Let’s see the second term:</p>
<p><span class="math display">
\sigma'(z^L_j).
</span></p>
<p>The derivative of <span class="math inline">\sigma</span> depends on the specific function we choose. Let’s calculate what the answer would be for two commonly used activation functions, the sigmoid and relu. For the sigmoid:</p>
<p><span class="math display">\begin{align*}
\sigma(z) &amp;= \frac{1}{1+\exp(-z)} \\
\sigma'(z) &amp;= \sigma(z)\left(1-\sigma(z)\right).
\end{align*}</span></p>
<p>For the relu:</p>
<p><span class="math display">\begin{align*}
\sigma(z) &amp;= \max(0,z) \\
\sigma'(z) &amp;= \begin{cases}
0 &amp; z &lt; 0 \\
1 &amp; z &gt; 0
\end{cases}
\end{align*}</span></p>
<p>In either case, the derivative is easy to compute, and we have the Base Case of our induction.</p>
</section>
<section id="the-inductive-step-the-hidden-layers" class="level2" data-number="56.4">
<h2 data-number="56.4" class="anchored" data-anchor-id="the-inductive-step-the-hidden-layers"><span class="header-section-number">56.4</span> the inductive step: the hidden layers</h2>
<p>The arguments here are also based on a bunch of partial derivatives and the chain rule. We start from the error in a generic hidden layer <span class="math inline">\ell</span>:</p>
<p><span class="math display">
\delta^\ell_j = \frac{\partial C}{\partial z^\ell_j}.
</span></p>
<p>This error is influenced by the errors in the next layer <span class="math inline">\ell+1</span>, so we now use the chain rule to express this relationship:</p>
<p><span class="math display">
\delta^\ell_j = \sum_k \frac{\partial C}{\partial z^{\ell+1}_k} \frac{\partial z^{\ell+1}_k}{\partial z^\ell_j} = \underbrace{\sum_k \delta^{\ell+1}_k \frac{\partial z^{\ell+1}_k}{\partial z^\ell_j}}_{\text{summation over layer $\ell+1$}}.
</span></p>
<p>Let’s interpret this equation, using the image below to help us. We are already used to the idea that the activation of a neuron in layer <span class="math inline">\ell</span> propagates to the next layer <span class="math inline">\ell+1</span>, from left to right. This is what the blue lines in the image below represent.</p>
<p>The conceptual jump now is to use these same lines to understand how the error in layer <span class="math inline">\ell+1</span> <strong>propagates back</strong> to layer <span class="math inline">\ell</span>, from right to left. The equation above says that the error in layer <span class="math inline">\ell</span> is the sum of the errors in layer <span class="math inline">\ell+1</span>, weighted by something that should be related to the strength of the connection between the neurons in layer <span class="math inline">\ell</span> and layer <span class="math inline">\ell+1</span>.</p>
<div id="7eeadace" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb3-2"><a href="#cb3-2"></a></span>
<span id="cb3-3"><a href="#cb3-3"></a>layer_left <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>layer_right <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>ms <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer_left):</span>
<span id="cb3-7"><a href="#cb3-7"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(layer_right):</span>
<span id="cb3-8"><a href="#cb3-8"></a>        <span class="cf">if</span> i <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb3-9"><a href="#cb3-9"></a>            color <span class="op">=</span> <span class="st">"xkcd:cerulean"</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>            alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb3-11"><a href="#cb3-11"></a>        <span class="cf">else</span>:</span>
<span id="cb3-12"><a href="#cb3-12"></a>            alpha <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>            color <span class="op">=</span> <span class="st">"gray"</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>        ax.plot([<span class="dv">0</span>, <span class="dv">1</span>], [(layer_left <span class="op">-</span> i)<span class="op">/</span>layer_left, (layer_right <span class="op">-</span> j <span class="op">+</span> <span class="fl">1.5</span>)<span class="op">/</span>layer_left], </span>
<span id="cb3-15"><a href="#cb3-15"></a>                color<span class="op">=</span>color, lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span>alpha)</span>
<span id="cb3-16"><a href="#cb3-16"></a>        </span>
<span id="cb3-17"><a href="#cb3-17"></a></span>
<span id="cb3-18"><a href="#cb3-18"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer_left):</span>
<span id="cb3-19"><a href="#cb3-19"></a>    <span class="cf">if</span> i <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb3-20"><a href="#cb3-20"></a>        color <span class="op">=</span> <span class="st">"xkcd:vermillion"</span></span>
<span id="cb3-21"><a href="#cb3-21"></a>        alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb3-22"><a href="#cb3-22"></a>    <span class="cf">else</span>:</span>
<span id="cb3-23"><a href="#cb3-23"></a>        color <span class="op">=</span> <span class="st">"white"</span></span>
<span id="cb3-24"><a href="#cb3-24"></a>        alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb3-25"><a href="#cb3-25"></a>    ax.plot([<span class="dv">0</span>], [(layer_left <span class="op">-</span> i)<span class="op">/</span>layer_left], ls<span class="op">=</span><span class="st">'None'</span>, marker<span class="op">=</span><span class="st">'o'</span>, mfc<span class="op">=</span>color, </span>
<span id="cb3-26"><a href="#cb3-26"></a>            mec<span class="op">=</span><span class="st">"gray"</span>, markersize<span class="op">=</span>ms, alpha<span class="op">=</span>alpha)</span>
<span id="cb3-27"><a href="#cb3-27"></a>    ax.text(<span class="op">-</span><span class="fl">0.1</span>, (layer_left <span class="op">-</span> i)<span class="op">/</span>layer_left, <span class="vs">fr"</span><span class="dv">$\d</span><span class="vs">elta_</span><span class="sc">{</span>i<span class="sc">}</span><span class="dv">^</span><span class="er">\</span><span class="vs">ell</span><span class="dv">$</span><span class="vs">"</span>, </span>
<span id="cb3-28"><a href="#cb3-28"></a>                va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'right'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb3-29"><a href="#cb3-29"></a>    </span>
<span id="cb3-30"><a href="#cb3-30"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer_right):</span>
<span id="cb3-31"><a href="#cb3-31"></a>    color <span class="op">=</span> <span class="st">"xkcd:goldenrod"</span></span>
<span id="cb3-32"><a href="#cb3-32"></a>    ax.plot([<span class="dv">1</span>], [(layer_right <span class="op">-</span> i <span class="op">+</span> <span class="fl">1.5</span>)<span class="op">/</span>layer_left], ls<span class="op">=</span><span class="st">'None'</span>, marker<span class="op">=</span><span class="st">'o'</span>, mfc<span class="op">=</span>color, </span>
<span id="cb3-33"><a href="#cb3-33"></a>            mec<span class="op">=</span><span class="st">"gray"</span>, markersize<span class="op">=</span>ms)</span>
<span id="cb3-34"><a href="#cb3-34"></a>    ax.text(<span class="fl">1.1</span>, (layer_right <span class="op">-</span> i <span class="op">+</span> <span class="fl">1.5</span>)<span class="op">/</span>layer_left, <span class="vs">fr"</span><span class="dv">$\d</span><span class="vs">elta_</span><span class="sc">{</span>i<span class="sc">}</span><span class="dv">^</span><span class="ch">{{</span><span class="er">\</span><span class="vs">ell</span><span class="op">+</span><span class="vs">1</span><span class="ch">}}</span><span class="dv">$</span><span class="vs">"</span>, </span>
<span id="cb3-35"><a href="#cb3-35"></a>                va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'left'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb3-36"><a href="#cb3-36"></a></span>
<span id="cb3-37"><a href="#cb3-37"></a><span class="co"># ax.text(0.5, 0.9, r"$w_{ij}$", fontsize=12, color="gray")</span></span>
<span id="cb3-38"><a href="#cb3-38"></a>ax.text(<span class="dv">0</span>, <span class="dv">0</span>, <span class="vs">r"layer </span><span class="dv">$</span><span class="er">\</span><span class="vs">ell</span><span class="dv">$</span><span class="vs">"</span>, va<span class="op">=</span><span class="st">"top"</span>, ha<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb3-39"><a href="#cb3-39"></a>ax.text(<span class="dv">1</span>, <span class="dv">0</span>, <span class="vs">r"layer </span><span class="dv">$</span><span class="er">\</span><span class="vs">ell</span><span class="op">+</span><span class="vs">1</span><span class="dv">$</span><span class="vs">"</span>, va<span class="op">=</span><span class="st">"top"</span>, ha<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb3-40"><a href="#cb3-40"></a></span>
<span id="cb3-41"><a href="#cb3-41"></a>ax.<span class="bu">set</span>(xlim<span class="op">=</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.5</span>), ylim<span class="op">=</span>(<span class="dv">0</span>, <span class="fl">1.1</span>), xticks<span class="op">=</span>[], yticks<span class="op">=</span>[])</span>
<span id="cb3-42"><a href="#cb3-42"></a>ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb3-43"><a href="#cb3-43"></a>ax.axis(<span class="st">'off'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="nielsen_ch2_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We need now to evaluate the term</p>
<p><span class="math display">
\frac{\partial z^{\ell+1}_k}{\partial z^\ell_j}.
</span></p>
<p>Remember that the weighted input <span class="math inline">z</span>, at the <span class="math inline">k</span>-th neuron in layer <span class="math inline">\ell+1</span>, is defined as</p>
<p><span class="math display">
z^{\ell+1}_k = \sum_j w_{kj}^{\ell+1} a^\ell_j + b_k^{\ell+1}.
</span></p>
<p>Remember also that the activation <span class="math inline">a</span> is a function of the weighted input <span class="math inline">z</span>, <span class="math inline">a = \sigma(z)</span>. Putting all this together gives</p>
<p><span class="math display">\begin{align*}
\frac{\partial z^{\ell+1}_k}{\partial z^\ell_j} &amp;= \frac{\partial z^{\ell+1}_k}{\partial a^\ell_j} \cdot \frac{\partial a^\ell_j}{\partial z^\ell_j} \\
&amp;= w_{kj}^{\ell+1} \sigma'(z^\ell_j).
\end{align*}</span></p>
<p>Finally, we can rewrite the error in layer <span class="math inline">\ell</span> as</p>
<p><span class="math display">
\delta^\ell_j = \sum_k \delta^{\ell+1}_k w_{kj}^{\ell+1} \sigma'(z^\ell_j).
</span></p>
<p>Once more, all the terms in the right hand side of the equation above are easy to compute, and we have the Inductive Step of our argument.</p>
</section>
<section id="summary" class="level2" data-number="56.5">
<h2 data-number="56.5" class="anchored" data-anchor-id="summary"><span class="header-section-number">56.5</span> summary</h2>
<p>We’ve learned the following. For each weight and bias <span class="math inline">j</span> in any layer <span class="math inline">\ell</span>, we can compute the error <span class="math inline">\delta^\ell_j</span> and update the parameters according to:</p>
<p><span class="math display">\begin{align*}
w_{jk}^\ell &amp;\leftarrow w_{jk}^\ell - \eta a^{\ell-1}_k \delta_j^\ell \\ \\
b_j^\ell &amp;\leftarrow b_j^\ell - \eta \delta_j^\ell.
\end{align*}</span></p>
<p>The backpropagation algorithm tells us to start from the last layer, compute the error there, and then work our way back to the first layer, computing the error in each layer and updating the parameters accordingly. The errors in the last layer are:</p>
<p><span class="math display">
\delta^L_j = \left[ \frac{1}{n}\sum_x \sum_k(y_k - a_k^L) \right] \cdot \sigma'(z^L_j),
</span></p>
<p>and the errors in the hidden layers are:</p>
<p><span class="math display">
\delta^\ell_j = \sum_k \delta^{\ell+1}_k w_{kj}^{\ell+1} \sigma'(z^\ell_j).
</span></p>
</section>
<section id="batches" class="level2" data-number="56.6">
<h2 data-number="56.6" class="anchored" data-anchor-id="batches"><span class="header-section-number">56.6</span> batches</h2>
<p>Instead of computing the cost and the errors for the entire dataset, we can do it for a small random sample of the data, called a batch. We just need to reinterpret the summation over <span class="math inline">x</span> in the equations above as a summation over the batch. This is what stochastic gradient descent does. It allows us to update the parameters more frequently, and it also adds some noise to the process, which makes our descent in the cost landscape less smooth, but can also help to escape local minima.</p>
<p>We start by shuffling our dataset, and then splitting it into batches. Then, for each batch, we perform:</p>
<ol type="1">
<li>the feedforward algorithm to compute the activations and weighted inputs for each layer, and finally the cost for the batch;</li>
<li>the backpropagation algorithm to compute the errors for each layer.</li>
<li>the update of the parameters according to the equations above.</li>
</ol>
<p>Once we’ve done this for all batches, we have gone through the whole dataset, and we call this one <strong>epoch</strong> of training. We can repeat this process for as many epochs as we want, until the cost is sufficiently low. We usually test the performance of our network on a separate test set, and track it as a function of the number of epochs.</p>
</section>
<section id="vectorizing-nielsens-backpropagation-code" class="level2" data-number="56.7">
<h2 data-number="56.7" class="anchored" data-anchor-id="vectorizing-nielsens-backpropagation-code"><span class="header-section-number">56.7</span> vectorizing Nielsen’s backpropagation code</h2>
<p>Nielsen mentions in the book that the code, as it is written, is not optimized. He proposes the following problem to solve:</p>
<blockquote class="blockquote">
<p><strong>Fully matrix-based approach to backpropagation over a mini-batch</strong><br>
Our implementation of stochastic gradient descent loops over training examples in a mini-batch. It’s possible to modify the backpropagation algorithm so that it computes the gradients for all training examples in a mini-batch simultaneously. The idea is that instead of beginning with a single input vector, x, we can begin with a matrix X=[x1x2…xm] whose columns are the vectors in the mini-batch. We forward-propagate by multiplying by the weight matrices, adding a suitable matrix for the bias terms, and applying the sigmoid function everywhere. We backpropagate along similar lines. Explicitly write out pseudocode for this approach to the backpropagation algorithm. Modify network.py so that it uses this fully matrix-based approach. The advantage of this approach is that it takes full advantage of modern libraries for linear algebra. As a result it can be quite a bit faster than looping over the mini-batch. (On my laptop, for example, the speedup is about a factor of two when run on MNIST classification problems like those we considered in the last chapter.) In practice, all serious libraries for backpropagation use this fully matrix-based approach or some variant.</p>
</blockquote>
<p>I’ll write below the actual code, not the pseudocode. I’ll then compare the performance of the vectorized code with the original code, and see if I can get a speedup of about a factor of two, as Nielsen claims.</p>
<p>Note: I’ve made a few updates to the original code in the book. In general, I wrote it to be more “modern” (I’m writing this in 2026). Also, I made sure I didn’t copy and paste anything, I’m typing it myself so I take ownership of this code. Here are the major modifications in this chapter:</p>
<ol type="1">
<li>I’ve added ReLU as the default activation function, but you can choose sigmoid if you want.</li>
<li>I added a progress bar to the training loop using <code>tqdm</code> to visualize the training progress.</li>
<li>You can quit training early by pressing <code>Ctrl+C</code>, the model will keep the weights without raising an error.</li>
<li>I’ve vectorized the backpropagation algorithm to handle batches efficiently, which should speed up training significantly.</li>
</ol>
<div id="40afa7a0" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="co">"""The sigmoid function, JIT-compiled for speed."""</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>    <span class="cf">return</span> <span class="fl">1.0</span> <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb4-4"><a href="#cb4-4"></a></span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="kw">def</span> relu(z):</span>
<span id="cb4-6"><a href="#cb4-6"></a>    <span class="co">"""The ReLU function, JIT-compiled for speed."""</span></span>
<span id="cb4-7"><a href="#cb4-7"></a>    <span class="cf">return</span> np.maximum(<span class="dv">0</span>, z)</span>
<span id="cb4-8"><a href="#cb4-8"></a></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="kw">def</span> sigmoid_prime(z):</span>
<span id="cb4-10"><a href="#cb4-10"></a>    <span class="co">"""Derivative of the sigmoid function, JIT-compiled for speed."""</span></span>
<span id="cb4-11"><a href="#cb4-11"></a>    s <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb4-12"><a href="#cb4-12"></a>    <span class="cf">return</span> s <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> s)</span>
<span id="cb4-13"><a href="#cb4-13"></a></span>
<span id="cb4-14"><a href="#cb4-14"></a><span class="kw">def</span> relu_prime(z):</span>
<span id="cb4-15"><a href="#cb4-15"></a>    <span class="co">"""Derivative of the ReLU function, JIT-compiled for speed."""</span></span>
<span id="cb4-16"><a href="#cb4-16"></a>    <span class="cf">return</span> np.where(z <span class="op">&gt;</span> <span class="dv">0</span>, <span class="fl">1.0</span>, <span class="fl">0.0</span>)</span>
<span id="cb4-17"><a href="#cb4-17"></a></span>
<span id="cb4-18"><a href="#cb4-18"></a><span class="kw">class</span> NN:</span>
<span id="cb4-19"><a href="#cb4-19"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layer_sizes, rand_seed<span class="op">=</span><span class="dv">0</span>, activation<span class="op">=</span><span class="st">"relu"</span>, cost<span class="op">=</span><span class="st">"mse"</span>):</span>
<span id="cb4-20"><a href="#cb4-20"></a>        <span class="co">"""Initialize the neural network with the given layer sizes.</span></span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="co">        For example, if layer_sizes = [50, 15, 20, 10], then we have a</span></span>
<span id="cb4-22"><a href="#cb4-22"></a><span class="co">        network with 50 input neurons, 15 neurons in hidden layer 0,</span></span>
<span id="cb4-23"><a href="#cb4-23"></a><span class="co">        20 neurons in hidden layer 1, and 10 output neurons (layer 3).</span></span>
<span id="cb4-24"><a href="#cb4-24"></a><span class="co">        """</span></span>
<span id="cb4-25"><a href="#cb4-25"></a>        <span class="va">self</span>.number_of_layers <span class="op">=</span> <span class="bu">len</span>(layer_sizes) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb4-26"><a href="#cb4-26"></a>        <span class="va">self</span>.layer_sizes <span class="op">=</span> layer_sizes</span>
<span id="cb4-27"><a href="#cb4-27"></a>        <span class="va">self</span>.activation <span class="op">=</span> activation</span>
<span id="cb4-28"><a href="#cb4-28"></a>        <span class="va">self</span>.rng <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>rand_seed)</span>
<span id="cb4-29"><a href="#cb4-29"></a>        <span class="cf">if</span> activation <span class="op">==</span> <span class="st">'relu'</span>:</span>
<span id="cb4-30"><a href="#cb4-30"></a>            <span class="va">self</span>.activation_func <span class="op">=</span> relu</span>
<span id="cb4-31"><a href="#cb4-31"></a>            <span class="va">self</span>.activation_prime <span class="op">=</span> relu_prime</span>
<span id="cb4-32"><a href="#cb4-32"></a>        <span class="cf">elif</span> activation <span class="op">==</span> <span class="st">'sigmoid'</span>:</span>
<span id="cb4-33"><a href="#cb4-33"></a>            <span class="va">self</span>.activation_func <span class="op">=</span> sigmoid</span>
<span id="cb4-34"><a href="#cb4-34"></a>            <span class="va">self</span>.activation_prime <span class="op">=</span> sigmoid_prime</span>
<span id="cb4-35"><a href="#cb4-35"></a>        <span class="cf">else</span>:</span>
<span id="cb4-36"><a href="#cb4-36"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported activation function. Use 'relu' or 'sigmoid'."</span>)</span>
<span id="cb4-37"><a href="#cb4-37"></a>        <span class="cf">if</span> cost <span class="op">==</span> <span class="st">'mse'</span>:</span>
<span id="cb4-38"><a href="#cb4-38"></a>            <span class="va">self</span>.cost_func <span class="op">=</span> <span class="kw">lambda</span> output, target: np.mean((output <span class="op">-</span> target) <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb4-39"><a href="#cb4-39"></a>            <span class="va">self</span>.cost_derivative <span class="op">=</span> <span class="kw">lambda</span> output, target: (output <span class="op">-</span> target)</span>
<span id="cb4-40"><a href="#cb4-40"></a>        <span class="cf">else</span>:</span>
<span id="cb4-41"><a href="#cb4-41"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported cost function. Use 'mse'."</span>)</span>
<span id="cb4-42"><a href="#cb4-42"></a>        <span class="co"># randomly initialize weights and biases</span></span>
<span id="cb4-43"><a href="#cb4-43"></a>        <span class="co"># input layer has no weights nor biases, so we skip it.</span></span>
<span id="cb4-44"><a href="#cb4-44"></a>        rng <span class="op">=</span> np.random.default_rng(seed<span class="op">=</span>rand_seed)</span>
<span id="cb4-45"><a href="#cb4-45"></a>        <span class="co"># each neuron get 1 bias, so bias vector has the size of the layer</span></span>
<span id="cb4-46"><a href="#cb4-46"></a>        <span class="co"># we skip the first (input) layer, it doesn't have biases</span></span>
<span id="cb4-47"><a href="#cb4-47"></a>        <span class="co"># I made the biases to be matrices of shape (N_b, 1) instead of vectors of shape (N_b,)</span></span>
<span id="cb4-48"><a href="#cb4-48"></a>        <span class="co"># to make the broadcasting work more smoothly in the feedforward and backpropagation functions.</span></span>
<span id="cb4-49"><a href="#cb4-49"></a>        <span class="va">self</span>.biases <span class="op">=</span> [rng.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span>(N_b, <span class="dv">1</span>))</span>
<span id="cb4-50"><a href="#cb4-50"></a>                       <span class="cf">for</span> N_b <span class="kw">in</span> layer_sizes[<span class="dv">1</span>:]]</span>
<span id="cb4-51"><a href="#cb4-51"></a>        <span class="co"># each neuron in layer Right is connected to all neurons in layer Left,</span></span>
<span id="cb4-52"><a href="#cb4-52"></a>        <span class="co"># so weight matrix has the shape (size_right, size_left)</span></span>
<span id="cb4-53"><a href="#cb4-53"></a>        <span class="co"># again, we skip the first (input) layer, it doesn't have weights</span></span>
<span id="cb4-54"><a href="#cb4-54"></a>        <span class="co"># scale_for_weights = np.sqrt(2.0/size_left)</span></span>
<span id="cb4-55"><a href="#cb4-55"></a>        scale_for_weights <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-56"><a href="#cb4-56"></a>        <span class="va">self</span>.weights <span class="op">=</span> [rng.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span>scale_for_weights, size<span class="op">=</span>(size_right, size_left))</span>
<span id="cb4-57"><a href="#cb4-57"></a>                        <span class="cf">for</span> size_left, size_right <span class="kw">in</span></span>
<span id="cb4-58"><a href="#cb4-58"></a>                          <span class="bu">zip</span>(layer_sizes[:<span class="op">-</span><span class="dv">1</span>],layer_sizes[<span class="dv">1</span>:])</span>
<span id="cb4-59"><a href="#cb4-59"></a>                        ]</span>
<span id="cb4-60"><a href="#cb4-60"></a>    </span>
<span id="cb4-61"><a href="#cb4-61"></a>    <span class="kw">def</span> feedforward(<span class="va">self</span>, a):</span>
<span id="cb4-62"><a href="#cb4-62"></a>        <span class="co">"""given input `a` from the first layer,</span></span>
<span id="cb4-63"><a href="#cb4-63"></a><span class="co">           we sequencially compute the activations of each layer</span></span>
<span id="cb4-64"><a href="#cb4-64"></a><span class="co">           `feedforward` returns the activations of last (output) layer</span></span>
<span id="cb4-65"><a href="#cb4-65"></a><span class="co">        """</span></span>
<span id="cb4-66"><a href="#cb4-66"></a>        <span class="cf">for</span> b, w <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.biases, <span class="va">self</span>.weights):</span>
<span id="cb4-67"><a href="#cb4-67"></a>            z <span class="op">=</span> np.dot(w, a) <span class="op">+</span> b</span>
<span id="cb4-68"><a href="#cb4-68"></a>            a <span class="op">=</span> <span class="va">self</span>.activation_func(z)</span>
<span id="cb4-69"><a href="#cb4-69"></a>        <span class="cf">return</span> a</span>
<span id="cb4-70"><a href="#cb4-70"></a>    </span>
<span id="cb4-71"><a href="#cb4-71"></a>    <span class="kw">def</span> stochastic_gradient_descent(<span class="va">self</span>, training_data, epochs, batch_size, eta, test_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-72"><a href="#cb4-72"></a>        n <span class="op">=</span> <span class="bu">len</span>(training_data)</span>
<span id="cb4-73"><a href="#cb4-73"></a>        <span class="cf">try</span>:</span>
<span id="cb4-74"><a href="#cb4-74"></a>            <span class="cf">for</span> epoch_j <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb4-75"><a href="#cb4-75"></a>                <span class="co"># shuffle training data at the beginning of each epoch</span></span>
<span id="cb4-76"><a href="#cb4-76"></a>                <span class="va">self</span>.rng.shuffle(training_data)</span>
<span id="cb4-77"><a href="#cb4-77"></a>                <span class="co"># split training data into batches</span></span>
<span id="cb4-78"><a href="#cb4-78"></a>                batches <span class="op">=</span> [</span>
<span id="cb4-79"><a href="#cb4-79"></a>                    training_data[k:k<span class="op">+</span>batch_size]</span>
<span id="cb4-80"><a href="#cb4-80"></a>                    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n, batch_size)</span>
<span id="cb4-81"><a href="#cb4-81"></a>                ]</span>
<span id="cb4-82"><a href="#cb4-82"></a></span>
<span id="cb4-83"><a href="#cb4-83"></a>                start_time <span class="op">=</span> time.perf_counter()</span>
<span id="cb4-84"><a href="#cb4-84"></a>                <span class="co"># ASCII Progress bar with Epoch X/Y description</span></span>
<span id="cb4-85"><a href="#cb4-85"></a>                pbar <span class="op">=</span> tqdm(batches,</span>
<span id="cb4-86"><a href="#cb4-86"></a>                            desc<span class="op">=</span><span class="ss">f"Epoch </span><span class="sc">{</span>epoch_j<span class="op">+</span><span class="dv">1</span><span class="sc">:2}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb4-87"><a href="#cb4-87"></a>                            bar_format<span class="op">=</span><span class="st">'</span><span class="sc">{desc}</span><span class="st">: </span><span class="sc">{percentage:3.0f}</span><span class="st">%|</span><span class="sc">{bar}</span><span class="st">| </span><span class="sc">{elapsed}</span><span class="st">'</span>,</span>
<span id="cb4-88"><a href="#cb4-88"></a>                            leave<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-89"><a href="#cb4-89"></a>                    </span>
<span id="cb4-90"><a href="#cb4-90"></a>                <span class="co"># now loop over batches, update weights</span></span>
<span id="cb4-91"><a href="#cb4-91"></a>                <span class="cf">for</span> batch <span class="kw">in</span> pbar:</span>
<span id="cb4-92"><a href="#cb4-92"></a>                    <span class="va">self</span>.update_params_batch(batch, eta)</span>
<span id="cb4-93"><a href="#cb4-93"></a>                </span>
<span id="cb4-94"><a href="#cb4-94"></a>                pbar.close()</span>
<span id="cb4-95"><a href="#cb4-95"></a>                duration_seconds <span class="op">=</span> time.perf_counter() <span class="op">-</span> start_time</span>
<span id="cb4-96"><a href="#cb4-96"></a>                runtime_str <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>duration_seconds<span class="sc">:.3f}</span><span class="ss"> seconds"</span></span>
<span id="cb4-97"><a href="#cb4-97"></a>                msg <span class="op">=</span> <span class="st">""</span></span>
<span id="cb4-98"><a href="#cb4-98"></a>                <span class="cf">if</span> test_data:</span>
<span id="cb4-99"><a href="#cb4-99"></a>                    accuracy <span class="op">=</span> <span class="va">self</span>.evaluate(test_data)</span>
<span id="cb4-100"><a href="#cb4-100"></a>                    msg <span class="op">=</span> <span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy<span class="op">/</span><span class="bu">len</span>(test_data)<span class="sc">:.2%}</span><span class="ss"> | "</span>  <span class="co"># ({accuracy}/{len(test_data)})</span></span>
<span id="cb4-101"><a href="#cb4-101"></a>                msg <span class="op">+=</span> <span class="ss">f"Runtime: </span><span class="sc">{</span>runtime_str<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb4-102"><a href="#cb4-102"></a>                <span class="bu">print</span>(msg)</span>
<span id="cb4-103"><a href="#cb4-103"></a>                </span>
<span id="cb4-104"><a href="#cb4-104"></a>        <span class="cf">except</span> <span class="pp">KeyboardInterrupt</span>:</span>
<span id="cb4-105"><a href="#cb4-105"></a>            <span class="cf">if</span> <span class="st">'pbar'</span> <span class="kw">in</span> <span class="bu">locals</span>():</span>
<span id="cb4-106"><a href="#cb4-106"></a>                pbar.close()</span>
<span id="cb4-107"><a href="#cb4-107"></a>            <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">Training interrupted by user. Weights preserved."</span>)</span>
<span id="cb4-108"><a href="#cb4-108"></a>    </span>
<span id="cb4-109"><a href="#cb4-109"></a>    <span class="kw">def</span> update_params_batch(<span class="va">self</span>, batch, eta):</span>
<span id="cb4-110"><a href="#cb4-110"></a>        <span class="co"># 1. make input matrix, use column-major order, so each column is a training example, and each row is a feature.</span></span>
<span id="cb4-111"><a href="#cb4-111"></a>        <span class="co"># input = np.array([data[0] for data in batch]).T</span></span>
<span id="cb4-112"><a href="#cb4-112"></a>        <span class="co"># 2. make label matrix, use column-major order, so each column is a training example, and each row is a label.</span></span>
<span id="cb4-113"><a href="#cb4-113"></a>        <span class="co"># target = np.array([data[1] for data in batch]).T</span></span>
<span id="cb4-114"><a href="#cb4-114"></a>        <span class="bu">input</span> <span class="op">=</span> np.hstack([data[<span class="dv">0</span>].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="cf">for</span> data <span class="kw">in</span> batch])</span>
<span id="cb4-115"><a href="#cb4-115"></a>        target <span class="op">=</span> np.hstack([data[<span class="dv">1</span>].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="cf">for</span> data <span class="kw">in</span> batch])</span>
<span id="cb4-116"><a href="#cb4-116"></a>        <span class="co"># 3. compute the gradients for the whole batch using back propagation</span></span>
<span id="cb4-117"><a href="#cb4-117"></a>        nabla_b, nabla_w <span class="op">=</span> <span class="va">self</span>.back_propagation(<span class="bu">input</span>, target)</span>
<span id="cb4-118"><a href="#cb4-118"></a>        <span class="co"># update biases and weights</span></span>
<span id="cb4-119"><a href="#cb4-119"></a>        m <span class="op">=</span> <span class="bu">len</span>(batch)</span>
<span id="cb4-120"><a href="#cb4-120"></a>        <span class="va">self</span>.biases <span class="op">=</span> [</span>
<span id="cb4-121"><a href="#cb4-121"></a>            b <span class="op">-</span> (eta<span class="op">/</span>m) <span class="op">*</span> nb</span>
<span id="cb4-122"><a href="#cb4-122"></a>            <span class="cf">for</span> b, nb <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.biases, nabla_b)</span>
<span id="cb4-123"><a href="#cb4-123"></a>        ]</span>
<span id="cb4-124"><a href="#cb4-124"></a>        <span class="va">self</span>.weights <span class="op">=</span> [</span>
<span id="cb4-125"><a href="#cb4-125"></a>            w <span class="op">-</span> (eta<span class="op">/</span>m) <span class="op">*</span> nw</span>
<span id="cb4-126"><a href="#cb4-126"></a>            <span class="cf">for</span> w, nw <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.weights, nabla_w)</span>
<span id="cb4-127"><a href="#cb4-127"></a>        ]</span>
<span id="cb4-128"><a href="#cb4-128"></a>    </span>
<span id="cb4-129"><a href="#cb4-129"></a>    <span class="kw">def</span> back_propagation(<span class="va">self</span>, <span class="bu">input</span>, target):</span>
<span id="cb4-130"><a href="#cb4-130"></a>        <span class="co">###############################</span></span>
<span id="cb4-131"><a href="#cb4-131"></a>        <span class="co"># 1. forward pass</span></span>
<span id="cb4-132"><a href="#cb4-132"></a>        <span class="co"># 1a. create variables to store the activations and z vectors for each layer</span></span>
<span id="cb4-133"><a href="#cb4-133"></a>        <span class="co"># activation starts with the input layer activations, which is just the input data</span></span>
<span id="cb4-134"><a href="#cb4-134"></a>        activation <span class="op">=</span> <span class="bu">input</span></span>
<span id="cb4-135"><a href="#cb4-135"></a>        activation_list <span class="op">=</span> [<span class="bu">input</span>]  <span class="co"># initialize with input layer activations</span></span>
<span id="cb4-136"><a href="#cb4-136"></a>        <span class="co"># weighted input start at the first hidden layer, so we initialize an empty list</span></span>
<span id="cb4-137"><a href="#cb4-137"></a>        z_list <span class="op">=</span> []</span>
<span id="cb4-138"><a href="#cb4-138"></a>        <span class="co"># 1b. loop over layers in forward direction, starting from the first hidden layer,</span></span>
<span id="cb4-139"><a href="#cb4-139"></a>        <span class="co"># compute and store the activations and z vectors layer by layer</span></span>
<span id="cb4-140"><a href="#cb4-140"></a>        <span class="co"># for the whole batch at once.</span></span>
<span id="cb4-141"><a href="#cb4-141"></a>        <span class="cf">for</span> b, w <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.biases, <span class="va">self</span>.weights):</span>
<span id="cb4-142"><a href="#cb4-142"></a>            layer_size <span class="op">=</span> b.shape[<span class="dv">0</span>]</span>
<span id="cb4-143"><a href="#cb4-143"></a>            <span class="co"># b is a vector of shape (layer_size, 1), we need to broadcast it (stack it horizontally)</span></span>
<span id="cb4-144"><a href="#cb4-144"></a>            <span class="co"># to match the shape of the dot product w @ activation, which is (layer_size, batch_size)</span></span>
<span id="cb4-145"><a href="#cb4-145"></a>            B <span class="op">=</span> np.broadcast_to(b, (layer_size, <span class="bu">input</span>.shape[<span class="dv">1</span>]))</span>
<span id="cb4-146"><a href="#cb4-146"></a>            z <span class="op">=</span> np.dot(w, activation) <span class="op">+</span> B</span>
<span id="cb4-147"><a href="#cb4-147"></a>            activation <span class="op">=</span> <span class="va">self</span>.activation_func(z)</span>
<span id="cb4-148"><a href="#cb4-148"></a>            z_list.append(z)</span>
<span id="cb4-149"><a href="#cb4-149"></a>            activation_list.append(activation)</span>
<span id="cb4-150"><a href="#cb4-150"></a>        <span class="co">###############################</span></span>
<span id="cb4-151"><a href="#cb4-151"></a>        <span class="co"># now we have all the information we need to compute the gradients in the backward pass.</span></span>
<span id="cb4-152"><a href="#cb4-152"></a>        <span class="co">###############################</span></span>
<span id="cb4-153"><a href="#cb4-153"></a>        <span class="co"># 2. backward pass</span></span>
<span id="cb4-154"><a href="#cb4-154"></a>        <span class="co"># 2a. create empty lists to store the gradients for biases and weights, layer by layer</span></span>
<span id="cb4-155"><a href="#cb4-155"></a>        nabla_b <span class="op">=</span> [np.zeros_like(b) <span class="cf">for</span> b <span class="kw">in</span> <span class="va">self</span>.biases]</span>
<span id="cb4-156"><a href="#cb4-156"></a>        nabla_w <span class="op">=</span> [np.zeros_like(w) <span class="cf">for</span> w <span class="kw">in</span> <span class="va">self</span>.weights]</span>
<span id="cb4-157"><a href="#cb4-157"></a>        <span class="co"># 2b. first compute the error "delta" for the output layer</span></span>
<span id="cb4-158"><a href="#cb4-158"></a>        <span class="co"># this is what we called the "base case"</span></span>
<span id="cb4-159"><a href="#cb4-159"></a>        delta <span class="op">=</span> <span class="va">self</span>.cost_derivative(activation_list[<span class="op">-</span><span class="dv">1</span>], target) <span class="op">*</span> <span class="va">self</span>.activation_prime(z_list[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb4-160"><a href="#cb4-160"></a>        <span class="co"># 2c. compute and store the gradients for the output layer</span></span>
<span id="cb4-161"><a href="#cb4-161"></a>        <span class="co"># we use activation_list[-2] because the rule for updating the weights requires the activations from the previous layer,</span></span>
<span id="cb4-162"><a href="#cb4-162"></a>        <span class="co"># which is the second to last layer in the list. The transpose is needed to match the dimensions of the matrices</span></span>
<span id="cb4-163"><a href="#cb4-163"></a>        nabla_b[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> np.<span class="bu">sum</span>(delta, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-164"><a href="#cb4-164"></a>        nabla_w[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> np.dot(delta, activation_list[<span class="op">-</span><span class="dv">2</span>].T)</span>
<span id="cb4-165"><a href="#cb4-165"></a>        <span class="co"># 2c. loop over layers in reverse order,</span></span>
<span id="cb4-166"><a href="#cb4-166"></a>        <span class="co"># compute the gradients for each layer. This is the "inductive step".</span></span>
<span id="cb4-167"><a href="#cb4-167"></a>        <span class="co"># the loop starts at the second to last layer, and goes backwards to the first hidden layer.</span></span>
<span id="cb4-168"><a href="#cb4-168"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="va">self</span>.number_of_layers<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb4-169"><a href="#cb4-169"></a>            z <span class="op">=</span> z_list[<span class="op">-</span>l]</span>
<span id="cb4-170"><a href="#cb4-170"></a>            <span class="co"># the order of the dot product and the transpose of the weights are needed</span></span>
<span id="cb4-171"><a href="#cb4-171"></a>            <span class="co"># to match the dimensions of the matrices</span></span>
<span id="cb4-172"><a href="#cb4-172"></a>            delta <span class="op">=</span> np.dot(<span class="va">self</span>.weights[<span class="op">-</span>l<span class="op">+</span><span class="dv">1</span>].T, delta) <span class="op">*</span> <span class="va">self</span>.activation_prime(z)</span>
<span id="cb4-173"><a href="#cb4-173"></a>            nabla_b[<span class="op">-</span>l] <span class="op">=</span> np.<span class="bu">sum</span>(delta, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-174"><a href="#cb4-174"></a>            nabla_w[<span class="op">-</span>l] <span class="op">=</span> np.dot(delta, activation_list[<span class="op">-</span>l<span class="op">-</span><span class="dv">1</span>].T)</span>
<span id="cb4-175"><a href="#cb4-175"></a>        <span class="cf">return</span> nabla_b, nabla_w</span>
<span id="cb4-176"><a href="#cb4-176"></a>    </span>
<span id="cb4-177"><a href="#cb4-177"></a>    <span class="kw">def</span> evaluate(<span class="va">self</span>, test_data):</span>
<span id="cb4-178"><a href="#cb4-178"></a>        <span class="co">"""Return the number of correct classifications."""</span></span>
<span id="cb4-179"><a href="#cb4-179"></a>        test_results <span class="op">=</span> [(np.argmax(<span class="va">self</span>.feedforward(x)), y)</span>
<span id="cb4-180"><a href="#cb4-180"></a>                        <span class="cf">for</span> (x, y) <span class="kw">in</span> test_data]</span>
<span id="cb4-181"><a href="#cb4-181"></a>        <span class="cf">return</span> <span class="bu">sum</span>(<span class="bu">int</span>(x <span class="op">==</span> y) <span class="cf">for</span> (x, y) <span class="kw">in</span> test_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I heavily commented the code above, but I still don’t expect it to be understandable. The first time I tried to convert Nielsen’s code to a vectorized version, I used Gemini or ChatGPT, and it immediately spit out a fully functioning code. The structure of this new code was very similar to the original, but I couldn’t say that I understood the details of the matrix multiplications. I then decided to code it myself, and make sure I know exactly every step of the way. I knew I was doing something right when I ran into bugs for a full day. The code either didn’t run because of a shape mismatch, or it ran but the performance didn’t change at all as epochs went by. What was missing for me was pencil and paper work. I had to write down the shapes of all the matrices and vectors involved in the feedforward and backpropagation algorithms, and make sure they all matched up. Once I did that, I knew exactly what to fix, and voilà, the code worked. I know I will forget in 10 minutes why the code works, and from now on I’ll just believe that it does what it is supposed to do, but I’ll have the confidence that I understood it once, and that’s a great feeling to have. See below one of my pencil and paper notes, as a proof of my hard work.</p>
<p><img src="index_verification.png" class="img-fluid" width="400"></p>
<div id="c8846159" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>define function to load MNIST from web</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">def</span> load_mnist_from_web():</span>
<span id="cb5-2"><a href="#cb5-2"></a>    urls <span class="op">=</span> {</span>
<span id="cb5-3"><a href="#cb5-3"></a>        <span class="st">"train_img"</span>: <span class="st">"https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz"</span>,</span>
<span id="cb5-4"><a href="#cb5-4"></a>        <span class="st">"train_lbl"</span>: <span class="st">"https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz"</span>,</span>
<span id="cb5-5"><a href="#cb5-5"></a>        <span class="st">"test_img"</span>: <span class="st">"https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz"</span>,</span>
<span id="cb5-6"><a href="#cb5-6"></a>        <span class="st">"test_lbl"</span>: <span class="st">"https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz"</span></span>
<span id="cb5-7"><a href="#cb5-7"></a>    }</span>
<span id="cb5-8"><a href="#cb5-8"></a></span>
<span id="cb5-9"><a href="#cb5-9"></a>    data_results <span class="op">=</span> {}</span>
<span id="cb5-10"><a href="#cb5-10"></a></span>
<span id="cb5-11"><a href="#cb5-11"></a>    <span class="cf">for</span> key, url <span class="kw">in</span> urls.items():</span>
<span id="cb5-12"><a href="#cb5-12"></a>        <span class="bu">print</span>(<span class="ss">f"Fetching </span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb5-13"><a href="#cb5-13"></a>        response <span class="op">=</span> requests.get(url)</span>
<span id="cb5-14"><a href="#cb5-14"></a>        response.raise_for_status()</span>
<span id="cb5-15"><a href="#cb5-15"></a>        </span>
<span id="cb5-16"><a href="#cb5-16"></a>        <span class="co"># Wrap the content in BytesIO and decompress in memory</span></span>
<span id="cb5-17"><a href="#cb5-17"></a>        <span class="cf">with</span> gzip.GzipFile(fileobj<span class="op">=</span>io.BytesIO(response.content)) <span class="im">as</span> f:</span>
<span id="cb5-18"><a href="#cb5-18"></a>            <span class="cf">if</span> <span class="st">"img"</span> <span class="kw">in</span> key:</span>
<span id="cb5-19"><a href="#cb5-19"></a>                <span class="co"># Images: offset 16</span></span>
<span id="cb5-20"><a href="#cb5-20"></a>                data_results[key] <span class="op">=</span> np.frombuffer(f.read(), np.uint8, offset<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb5-21"><a href="#cb5-21"></a>            <span class="cf">else</span>:</span>
<span id="cb5-22"><a href="#cb5-22"></a>                <span class="co"># Labels: offset 8</span></span>
<span id="cb5-23"><a href="#cb5-23"></a>                data_results[key] <span class="op">=</span> np.frombuffer(f.read(), np.uint8, offset<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb5-24"><a href="#cb5-24"></a></span>
<span id="cb5-25"><a href="#cb5-25"></a>    <span class="co"># Re-format to Nielsen's expected structure</span></span>
<span id="cb5-26"><a href="#cb5-26"></a>    <span class="kw">def</span> vectorized_result(j):</span>
<span id="cb5-27"><a href="#cb5-27"></a>        e <span class="op">=</span> np.zeros((<span class="dv">10</span>, <span class="dv">1</span>))</span>
<span id="cb5-28"><a href="#cb5-28"></a>        e[j] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb5-29"><a href="#cb5-29"></a>        <span class="cf">return</span> e</span>
<span id="cb5-30"><a href="#cb5-30"></a></span>
<span id="cb5-31"><a href="#cb5-31"></a>    training_inputs <span class="op">=</span> [np.reshape(x, (<span class="dv">784</span>, <span class="dv">1</span>)) <span class="op">/</span> <span class="fl">255.0</span> <span class="cf">for</span> x <span class="kw">in</span> data_results[<span class="st">"train_img"</span>].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)]</span>
<span id="cb5-32"><a href="#cb5-32"></a>    training_results <span class="op">=</span> [vectorized_result(y) <span class="cf">for</span> y <span class="kw">in</span> data_results[<span class="st">"train_lbl"</span>]]</span>
<span id="cb5-33"><a href="#cb5-33"></a>    training_data <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(training_inputs, training_results))</span>
<span id="cb5-34"><a href="#cb5-34"></a></span>
<span id="cb5-35"><a href="#cb5-35"></a>    test_inputs <span class="op">=</span> [np.reshape(x, (<span class="dv">784</span>, <span class="dv">1</span>)) <span class="op">/</span> <span class="fl">255.0</span> <span class="cf">for</span> x <span class="kw">in</span> data_results[<span class="st">"test_img"</span>].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)]</span>
<span id="cb5-36"><a href="#cb5-36"></a>    test_data <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(test_inputs, data_results[<span class="st">"test_lbl"</span>]))</span>
<span id="cb5-37"><a href="#cb5-37"></a></span>
<span id="cb5-38"><a href="#cb5-38"></a>    <span class="cf">return</span> training_data, test_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="118b011b" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>load MNIST data into memory</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>training_data, test_data <span class="op">=</span> load_mnist_from_web()</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="bu">print</span>(<span class="ss">f"Loaded </span><span class="sc">{</span><span class="bu">len</span>(training_data)<span class="sc">}</span><span class="ss"> training samples directly into memory."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fetching train_img...
Fetching train_lbl...
Fetching test_img...
Fetching test_lbl...
Loaded 60000 training samples directly into memory.</code></pre>
</div>
</div>
<div id="0a7def0b" class="cell" data-execution_count="35">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>net <span class="op">=</span> NN(layer_sizes<span class="op">=</span>[<span class="dv">784</span>, <span class="dv">30</span>, <span class="dv">10</span>], activation<span class="op">=</span><span class="st">"sigmoid"</span>, rand_seed<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb8-2"><a href="#cb8-2"></a>net.stochastic_gradient_descent(training_data<span class="op">=</span>training_data,</span>
<span id="cb8-3"><a href="#cb8-3"></a>        epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb8-4"><a href="#cb8-4"></a>        batch_size<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb8-5"><a href="#cb8-5"></a>        eta<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb8-6"><a href="#cb8-6"></a>        test_data<span class="op">=</span>test_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  1/10: 100%|██████████| 00:00</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 71.84% | Runtime: 0.970 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  2/10: 100%|██████████| 00:00</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 89.66% | Runtime: 0.931 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  3/10: 100%|██████████| 00:00</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 91.49% | Runtime: 0.981 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  4/10: 100%|██████████| 00:00</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 92.00% | Runtime: 0.955 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  5/10: 100%|██████████| 00:00</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 92.45% | Runtime: 0.999 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  6/10: 100%|██████████| 00:01</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 92.44% | Runtime: 1.104 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  7/10: 100%|██████████| 00:01</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 93.05% | Runtime: 1.020 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  8/10: 100%|██████████| 00:00</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 93.29% | Runtime: 1.001 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch  9/10: 100%|██████████| 00:00</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 93.26% | Runtime: 0.982 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch 10/10: 100%|██████████| 00:01</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 93.55% | Runtime: 1.313 seconds</code></pre>
</div>
</div>
</section>
<section id="widget" class="level2" data-number="56.8">
<h2 data-number="56.8" class="anchored" data-anchor-id="widget"><span class="header-section-number">56.8</span> widget</h2>
<p>Let’s play with the trained model!</p>
<div id="390ec18a" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>export model parameters to JSON</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a>export_data <span class="op">=</span> {</span>
<span id="cb29-2"><a href="#cb29-2"></a>    <span class="st">"weights"</span>: [w.tolist() <span class="cf">for</span> w <span class="kw">in</span> net.weights],</span>
<span id="cb29-3"><a href="#cb29-3"></a>    <span class="st">"biases"</span>: [b.tolist() <span class="cf">for</span> b <span class="kw">in</span> net.biases],</span>
<span id="cb29-4"><a href="#cb29-4"></a>}</span>
<span id="cb29-5"><a href="#cb29-5"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">"mnist_model.json"</span>, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb29-6"><a href="#cb29-6"></a>    json.dump(export_data, f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="digit-widget-container" style="display: flex; flex-direction: column; align-items: center; gap: 20px; padding: 20px; background: #f8f9fa; border-radius: 10px; border: 1px solid #ddd; font-family: sans-serif; width: fit-content; margin: auto;">
    
    <div style="text-align: center;">
        <h3 id="prediction-text" style="margin: 0; color: #333;" class="anchored">Draw a number!</h3>
    </div>

    <div id="output-viz" style="display: flex; align-items: flex-end; gap: 8px; height: 100px; padding: 10px; border-bottom: 2px solid #ccc; width: 280px; justify-content: space-between;">
        </div>
    
    <canvas id="canvas" width="28" height="28" style="width: 280px; height: 280px; border: 2px solid #333; background: white; cursor: crosshair; touch-action: none; image-rendering: pixelated;"></canvas>
    
    <div style="display: flex; gap: 10px;">
        <button onclick="clearCanvas()" style="padding: 10px 20px; background: #dc3545; color: white; border: none; border-radius: 5px; cursor: pointer;">Clear</button>
        <button onclick="runPrediction()" style="padding: 10px 20px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer;">Predict</button>
    </div>
</div>

<script>
let model = null;
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d', { willReadFrequently: true });
const predictionText = document.getElementById('prediction-text');
const vizContainer = document.getElementById('output-viz');

// Bars Initialization
const bars = [];
for (let i = 0; i < 10; i++) {
    const wrapper = document.createElement('div');
    wrapper.style.display = 'flex'; wrapper.style.flexDirection = 'column';
    wrapper.style.alignItems = 'center'; wrapper.style.width = '20px';
    const bar = document.createElement('div');
    bar.style.width = '100%'; bar.style.height = '0px'; bar.style.backgroundColor = '#28a745';
    bar.style.transition = 'height 0.2s'; bar.style.borderRadius = '2px 2px 0 0';
    const label = document.createElement('span');
    label.innerText = i; label.style.fontSize = '12px';
    wrapper.appendChild(bar); wrapper.appendChild(label);
    vizContainer.appendChild(wrapper);
    bars.push(bar);
}

// Drawing Logic for 28x28
// We need to account for the scale factor (10x) when calculating mouse position
ctx.strokeStyle = 'black';
ctx.lineWidth = 1.2; // Small width for 28x28 grid
ctx.lineCap = 'round';

fetch('mnist_model.json').then(r => r.json()).then(d => model = d);

let isDrawing = false;
canvas.addEventListener('mousedown', () => isDrawing = true);
canvas.addEventListener('mousemove', draw);
canvas.addEventListener('mouseup', () => { isDrawing = false; ctx.beginPath(); });

function draw(e) {
    if (!isDrawing) return;
    const rect = canvas.getBoundingClientRect();
    // Scale the coordinates: (Actual Mouse Pos / Display Size) * Internal Size
    const x = (e.clientX - rect.left) * (canvas.width / rect.width);
    const y = (e.clientY - rect.top) * (canvas.height / rect.height);
    
    ctx.lineTo(x, y);
    ctx.stroke();
}

function clearCanvas() {
    ctx.clearRect(0, 0, 28, 28);
    predictionText.innerText = "28x28 Direct Input";
    bars.forEach(b => b.style.height = '0px');
}

const sigmoid = (z) => 1.0 / (1.0 + Math.exp(-z));

function runPrediction() {
    if (!model) return;
    const imgData = ctx.getImageData(0, 0, 28, 28).data;
    const input = [];
    
    for (let i = 0; i < imgData.length; i += 4) {
        // Since we draw black on a clear/white canvas, 
        // we use the Alpha channel (index i+3) as the "ink" intensity
        const alpha = imgData[i+3] / 255.0;
        input.push(alpha);
    }

    // Feedforward
    let a = input;
    for (let i = 0; i < model.weights.length; i++) {
        let w = model.weights[i], b = model.biases[i], next_a = [];
        for (let row = 0; row < w.length; row++) {
            let sum = 0;
            for (let col = 0; col < w[row].length; col++) {
                sum += w[row][col] * a[col];
            }
            next_a.push(sigmoid(sum + b[row][0]));
        }
        a = next_a;
    }

    const result = a.indexOf(Math.max(...a));
    predictionText.innerText = `Prediction: ${result}`;

    a.forEach((val, idx) => {
        bars[idx].style.height = `${val * 80}px`;
        bars[idx].style.backgroundColor = (idx === result) ? '#28a745' : '#adb5bd';
    });
}
</script>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../neural_networks/nielsen_ch1.html" class="pagination-link" aria-label="Nielsen's NNDL, ch.1">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Nielsen’s NNDL, ch.1</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../misc/trend_test.html" class="pagination-link" aria-label="trend test">
        <span class="nav-page-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">trend test</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>