{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"cosine\"\n",
    "execute:\n",
    "  # echo: false\n",
    "  freeze: auto  # re-render only when source changes\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-summary: \"Show the code\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the spirit of this website, beautiful things happen when we imagine data in high dimensional spaces. Let's do that for the correlation between two vectors.\n",
    "\n",
    "$$\n",
    "\\rho(x,y) = \\frac{1}{N} \\sum_{i=1}^N \\left(\\frac{x_i - \\bar{x}}{\\sigma_x}\\right)\\left(\\frac{y_i - \\bar{y}}{\\sigma_y}\\right)\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "As we [saw before](/correlation/correlation.html#covariance-of-z-scored-variables), it is particularly useful to rewrite this formula in terms of z-scored variables:\n",
    "\n",
    "$$\n",
    "\\rho(x,y) = \\frac{1}{N} \\sum_{i=1}^N z_{x_i} z_{y_i}\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "where $z_{x_i} = \\frac{x_i - \\bar{x}}{\\sigma_x}$ and $z_{y_i} = \\frac{y_i - \\bar{y}}{\\sigma_y}$.\n",
    "\n",
    "Now let's see the formula for the dot product of two vectors $z_x$ and $z_y$:\n",
    "\n",
    "$$\n",
    "z_x \\cdot z_y = \\sum_{i=1}^N z_{x_i} z_{y_i} = \\frac{1}{N} \\sum_{i=1}^N z_{x_i} z_{y_i} \\cdot N = \\rho(x,y) \\cdot N\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "There is another formula for the dot product that involves the angle $\\theta$ between the two vectors:\n",
    "\n",
    "$$\n",
    "z_x \\cdot z_y = \\lVert z_x \\rVert \\, \\lVert z_y \\rVert \\cos(\\theta)\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "where $||z_x||$ and $||z_y||$ are the magnitudes (or lengths) of the vectors $z_x$ and $z_y$.\n",
    "\n",
    "The magnitude squared of a z-scored vector is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\lVert z_x \\rVert ^2 &= \\sum_{i=1}^N z_{x_i}^2 \\\\\n",
    "                     &= \\sum_{i=1}^N \\left(\\frac{x_i - \\bar{x}}{\\sigma_x}\\right)^2 \\\\\n",
    "                     &= \\frac{1}{\\sigma_x^2} \\sum_{i=1}^N (x_i - \\bar{x})^2 \\\\\n",
    "                     &= \\frac{1}{\\sigma_x^2} \\left( \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2 \\right) N \\\\\n",
    "                     & = N\\frac{\\sigma_x^2}{\\sigma_x^2} \\\\\n",
    "                     &= N \\tag{5}\n",
    "\\end{align*}\n",
    "\n",
    "Of course, the same goes for $z_y$, so we have $\\lVert z_x \\rVert = \\lVert z_y \\rVert = \\sqrt{N}$. Substituting this into Eq. (4) gives:\n",
    "\n",
    "$$\n",
    "z_x \\cdot z_y = \\sqrt{N} \\cdot \\sqrt{N} \\cdot \\cos(\\theta) = N \\cos(\\theta)\n",
    "\\tag{6}\n",
    "$$\n",
    "\n",
    "Finally, we equate Eqs. (3) and (6):\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "$$\n",
    "\\rho(x,y) = \\cos(\\theta)\n",
    "\\tag{7}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "The correlation between two variables is equal to the cosine of the angle between their corresponding z-scored vectors, in a high-dimensional space.\n",
    "\n",
    "* $\\theta=0$,  the vectors point in the same direction, $\\cos(\\theta) = 1$, indicating a perfect positive correlation.\n",
    "* $\\theta=\\pi/2$, the vectors are orthogonal, $\\cos(\\theta) = 0$, indicating no correlation.\n",
    "* $\\theta=\\pi$, the vectors point in opposite directions, $\\cos(\\theta) = -1$, indicating a perfect negative correlation.\n",
    "\n",
    "## cosine similarity\n",
    "\n",
    "The cosine similarity is a measure of similarity between two non-zero vectors. It is defined as:\n",
    "\n",
    "$$\n",
    "\\text{cosine\\_similarity}(x,y) = \\frac{x \\cdot y}{\\lVert x \\rVert \\, \\lVert y \\rVert}\n",
    "\\tag{8}\n",
    "$$\n",
    "\n",
    "This measure is common in text analysis, where a non-zero element of a vector represents the presence of a word in a document, and the value of the element represents the frequency of that word. The cosine similarity measures the cosine of the angle between two vectors, which indicates how similar the two vectors are in terms of their direction, regardless of their magnitude. If we were to z-score the vectors, the absence of a word would be represented by a negative value (below average), which is not useful in this context.\n",
    "\n",
    "When the vectors are z-scored, the cosine similarity is identical to the Pearson correlation coefficient.\n",
    "\n",
    "* **cosine similarity**: works on any non-zero vectors, does not require z-scoring. There is no need to alter the reference point.\n",
    "* **Pearson correlation**: works on z-scored vectors, requires centering and scaling. The reference point is the mean of each variable. Useful when comparing variables with different units or scales."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
