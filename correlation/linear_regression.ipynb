{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"correlation and linear regression\"\n",
    "execute:\n",
    "  # echo: false\n",
    "  freeze: auto  # re-render only when source changes\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-summary: \"Show the code\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient is closely related to linear regression. We will see below a few instances of this relationship.\n",
    "\n",
    "## prelude: finding the intercept and slope\n",
    "\n",
    "Let's derive the formulas for the intercept and slope of the regression line. We want to minimize the sum of squared residuals $L$:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2,\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\beta_0 + \\beta_1 x_i.\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "To find the optimal values of $\\beta_0$ and $\\beta_1$, we take the partial derivatives of $L$ with respect to $\\beta_0$ and $\\beta_1$, set them to zero, and solve the resulting equations.\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\beta_0} &= 0 \\tag{3a}\\\\\n",
    "\\frac{\\partial L}{\\partial \\beta_1} &= 0 \\tag{3b}\n",
    "\\end{align*}\n",
    "\n",
    "[We already did that for a general case](/regression/equivalence.html#optimization), but the calculation had the variables in vector/matrix form. Here we will do it for the simple case of one predictor variable, so that we can see the relationship with correlation more clearly.\n",
    "\n",
    "### intercept\n",
    "\n",
    "Let's start with Eq. (3a), and substitute into it Eq. (2):\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\beta_0} &= \\frac{\\partial}{\\partial \\beta_0} (y_i - \\hat{y}_i)^2 \\tag{4a} \\\\\n",
    "&= \\frac{\\partial}{\\partial \\beta_0} (y_i - \\beta_0 - \\beta_1 x_i)^2 \\tag{4b} \\\\\n",
    "&= -2 \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) = 0 \\tag{4c}\n",
    "\\end{align*}\n",
    "\n",
    "Eliminating the constant factor $-2$ and expanding the summation, we get:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n y_i - n \\beta_0 - \\beta_1 \\sum_{i=1}^n x_i = 0\n",
    "\\tag{5}\n",
    "$$\n",
    "\n",
    "We now divide by $n$ and rearrange to isolate $\\beta_0$:\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "$$\n",
    "\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\n",
    "\\tag{6}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "Note: we can rewrite equation (4c) as\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n (y_i - \\hat{y}_i) = \\sum_{i=1}^n \\text{residuals} = 0,\n",
    "$$\n",
    "\n",
    "which is a nice thing to know.\n",
    "\n",
    "### slope\n",
    "\n",
    "Now let's move on to Eq. (3b), and substitute the result of Eq. (6) into it:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\beta_1} &= \\frac{\\partial}{\\partial \\beta_1} (y_i - \\hat{y}_i)^2 \\tag{7a} \\\\\n",
    "&= \\frac{\\partial}{\\partial \\beta_1} (y_i - \\beta_0 - \\beta_1 x_i)^2 \\tag{7b} \\\\\n",
    "&= -2 \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) x_i = 0 \\tag{7c} \\\\\n",
    "&= -2 \\sum_{i=1}^n (y_i - \\bar{y} + \\beta_1 \\bar{x} - \\beta_1 x_i) x_i = 0 \\tag{7d}\n",
    "\\end{align*}\n",
    "\n",
    "Eliminating the constant factor $2$ and expanding the summation, we get:\n",
    "\n",
    "$$\n",
    "-\\sum_{i=1}^n x_i y_i + \\sum_{i=1}^n x_i \\bar{y} - \\beta_1 \\sum_{i=1}^n x_i \\bar{x} + \\beta_1 \\sum_{i=1}^n x_i^2 = 0\n",
    "\\tag{8}\n",
    "$$\n",
    "\n",
    "Let's group the terms involving $\\beta_1$ on one side and the rest on the other side:\n",
    "\n",
    "$$\n",
    "\\beta_1 \\left( \\sum_{i=1}^n x_i^2 - \\sum_{i=1}^n x_i \\bar{x} \\right) = \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\bar{y}\n",
    "\\tag{9}\n",
    "$$\n",
    "\n",
    "Isolating $\\beta_1$, we have:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{\\sum x_i y_i - \\sum x_i \\bar{y}}{\\sum x_i^2 - \\sum x_i \\bar{x}} = \\frac{\\text{numerator}}{\\text{denominator}}\n",
    "\\tag{10}\n",
    "$$\n",
    "\n",
    "It's easier to interpret the numerator and denominator separately. To each we will add and subtract a term that will allow us to express them in simpler forms.\n",
    "\n",
    "Numerator:\n",
    "\n",
    "$$\n",
    "\\text{numerator} = \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\bar{y} + \\sum_{i=1}^n \\bar{x} y_i - \\sum_{i=1}^n \\bar{x} y_i\n",
    "\\tag{11}\n",
    "$$\n",
    "\n",
    "We express the third term thus:\n",
    "\n",
    "$$\n",
    "\\text{third term} = \\sum_{i=1}^n \\bar{x} y_i = \\bar{x} \\sum_{i=1}^n y_i = n \\bar{x} \\bar{y} = \\sum_{i=1}^n \\bar{x} \\bar{y}\n",
    "\\tag{12}\n",
    "$$\n",
    "\n",
    "The numerator now becomes:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{numerator} &= \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\bar{y} + \\sum_{i=1}^n \\bar{x} \\bar{y} - \\sum_{i=1}^n \\bar{x} y_i \\tag{13a} \\\\\n",
    "&= \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) \\tag{13b} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now the denominator:\n",
    "\n",
    "$$\n",
    "\\text{denominator} = \\sum_{i=1}^n x_i^2 - \\sum_{i=1}^n x_i \\bar{x} + \\sum_{i=1}^n x_i\\bar{x} - \\sum_{i=1}^n x_i\\bar{x}\n",
    "\\tag{14}\n",
    "$$\n",
    "\n",
    "We group the second and fourth terms, and express the third term thus:\n",
    "\n",
    "$$\n",
    "\\text{third term} = \\sum_{i=1}^n x_i \\bar{x} = \\bar{x} \\sum_{i=1}^n x_i = n \\bar{x}^2 = \\sum_{i=1}^n \\bar{x}^2\n",
    "\\tag{15}\n",
    "$$\n",
    "\n",
    "The denominator now becomes:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{denominator} &= \\sum_{i=1}^n x_i^2 - 2 \\sum_{i=1}^n x_i \\bar{x} + \\sum_{i=1}^n \\bar{x}^2 \\tag{16a} \\\\\n",
    "&= \\sum_{i=1}^n (x_i - \\bar{x})^2 \\tag{16b}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Putting it all together, we have:\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "$$\n",
    "\\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\n",
    "\\tag{17}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "## slope and correlation\n",
    "\n",
    "Let's divide both the numerator and denominator of Eq. (17) by $n-1$:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}\n",
    "\\tag{18}\n",
    "$$\n",
    "\n",
    "The numerator is the sample covariance $\\text{cov}(X, Y)$, and the denominator is the sample variance $\\text{var}(X)$:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{\\text{cov}(X, Y)}{\\text{var}(X)}\n",
    "\\tag{19}\n",
    "$$\n",
    "\n",
    "Now, we can express the covariance in terms of the correlation coefficient $\\rho_{X,Y}$ and the standard deviations $\\sigma_X$ and $\\sigma_Y$ (see [here](/correlation/correlation.html#correlation)):\n",
    "\n",
    "$$\n",
    "\\text{cov}(X, Y) = \\rho_{X,Y} \\sigma_X \\sigma_Y\n",
    "\\tag{20}\n",
    "$$\n",
    "Substituting Eq. (20) into Eq. (19), we get:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{\\rho_{X,Y} \\sigma_X \\sigma_Y}{\\sigma_X^2}\n",
    "\\tag{21}\n",
    "$$\n",
    "\n",
    "And finally, we have:\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "$$\n",
    "\\beta_1 = \\rho_{X,Y} \\frac{\\sigma_Y}{\\sigma_X}\n",
    "\\tag{22}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "\n",
    "This shows that the slope of the regression line is directly proportional to the correlation coefficient. A higher absolute value of the correlation coefficient indicates a steeper slope, while a lower absolute value indicates a flatter slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $R^2=$ square of the correlation coefficient $r$\n",
    "\n",
    "Let's start by saying that the correlation coefficient is called $\\rho$ when referring to the population, and $r$ when referring to a sample. I'm playing loose with this convention here, but I hope it's clear from the context.\n",
    "\n",
    "Let's show now that the coefficient of determination $R^2$ is equal to the square of the correlation coefficient $r$.\n",
    "\n",
    "We start with the definition of $R^2$:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\text{SS}_{\\text{Error}}}{\\text{SS}_{\\text{Total}}} = \\frac{\\text{SS}_{\\text{Total}}+\\text{SS}_{\\text{Error}}}{\\text{SS}_{\\text{Total}}} =  \\frac{\\text{SS}_{\\text{Model}}}{\\text{SS}_{\\text{Total}}}\n",
    "\\tag{23}\n",
    "$$\n",
    "\n",
    "where we used the fact that $\\text{SS}_{\\text{Total}} = \\text{SS}_{\\text{Model}} + \\text{SS}_{\\text{Error}}$, [already seen before](/regression/partitioning.html).\n",
    "\n",
    "We now substitute into Eq. (23) the definitions of $\\text{SS}_{\\text{Model}}$ and $\\text{SS}_{\\text{Total}}$:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}\n",
    "\\tag{24}\n",
    "$$\n",
    "\n",
    "We now substitute into Eq. (24) the expression of $\\hat{y}_i$ from Eq. (2):\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\sum_{i=1}^n (\\beta_0 + \\beta_1 x_i - \\bar{y})^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}\n",
    "\\tag{25}\n",
    "$$\n",
    "\n",
    "Now we substitute into Eq. (25) the expression of $\\beta_0$ from Eq. (6):\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\sum_{i=1}^n \\left( \\bar{y} - \\beta_1 \\bar{x} + \\beta_1 x_i - \\bar{y} \\right)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} = \\frac{\\sum_{i=1}^n \\left( \\beta_1 (x_i - \\bar{x}) \\right)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}\n",
    "\\tag{26}\n",
    "$$\n",
    "\n",
    "$\\beta_1$ is a number, so we can take it out of the summation in the numerator:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\beta_1^2 \\sum_{i=1}^n (x_i - \\bar{x})^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}\n",
    "\\tag{26b}\n",
    "$$\n",
    "\n",
    "Now, let's substitute into Eq. (26) the expression of $\\beta_1$ from Eq. (17):\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\left( \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\right)^2 \\sum_{i=1}^n (x_i - \\bar{x})^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}\n",
    "\\tag{27}\n",
    "$$\n",
    "\n",
    "We can simplify Eq. (27) by canceling one instance of the denominator in the squared term with the factor outside the squared term:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\left[ \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) \\right]^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2 \\sum_{i=1}^n (y_i - \\bar{y})^2}\n",
    "\\tag{28}\n",
    "$$\n",
    "\n",
    "Now, let's multiply both the numerator and denominator of Eq. (28) by $\\frac{1}{(n-1)^2}$:\n",
    "\n",
    "$$  \n",
    "R^2 = \\frac{\\left[ \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) \\right]^2}{\\left[ \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 \\right] \\left[ \\frac{1}{n-1} \\sum_{i=1}^n (y_i - \\bar{y})^2 \\right]}\n",
    "\\tag{29}\n",
    "$$\n",
    "\n",
    "The numerator is the square of the sample covariance $\\text{cov}(X, Y)$, and the denominator is the product of the sample variances $\\text{var}(X)=\\sigma_X^2$ and $\\text{var}(Y)=\\sigma_Y^2$:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\text{cov}(X, Y)^2}{\\sigma_X^2 \\sigma_Y^2} = \\left( \\frac{\\text{cov}(X, Y)}{\\sigma_X \\sigma_Y} \\right)^2\n",
    "\\tag{30}\n",
    "$$\n",
    "\n",
    "This is exactly the square of the correlation coefficient $r$ (see [here](/correlation/correlation.html#correlation)):\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "$$\n",
    "R^2 = r^2\n",
    "\\tag{31}\n",
    "$$\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
