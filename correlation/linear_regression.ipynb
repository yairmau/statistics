{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"correlation and linear regression\"\n",
    "execute:\n",
    "  # echo: false\n",
    "  freeze: auto  # re-render only when source changes\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-summary: \"Show the code\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient is closely related to linear regression. In simple linear regression, we model the relationship between a dependent variable $Y$ and an independent variable $X$ as:\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X + \\epsilon\n",
    "$$\n",
    "where $\\beta_0$ is the intercept, $\\beta_1$ is the slope, and $\\epsilon$ is the error term.\n",
    "\n",
    "## prelude: finding the intercept and slope\n",
    "\n",
    "Let's derive the formulas for the intercept and slope of the regression line. We want to minimize the sum of squared residuals $L$:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2,\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\beta_0 + \\beta_1 x_i.\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "To find the optimal values of $\\beta_0$ and $\\beta_1$, we take the partial derivatives of $L$ with respect to $\\beta_0$ and $\\beta_1$, set them to zero, and solve the resulting equations.\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\beta_0} &= 0 \\tag{3a}\\\\\n",
    "\\frac{\\partial L}{\\partial \\beta_1} &= 0 \\tag{3b}\n",
    "\\end{align*}\n",
    "\n",
    "### intercept\n",
    "\n",
    "Let's start with Eq. (3a):\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\beta_0} &= \\frac{\\partial}{\\partial \\beta_0} (y_i - \\hat{y}_i)^2 \\tag{4a} \\\\\n",
    "&= \\frac{\\partial}{\\partial \\beta_0} (y_i - \\beta_0 - \\beta_1 x_i)^2 \\tag{4b} \\\\\n",
    "&= -2 \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) = 0 \\tag{4c}\n",
    "\\end{align*}\n",
    "\n",
    "Eliminating the constant factor $-2$ and expanding the summation, we get:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n y_i - n \\beta_0 - \\beta_1 \\sum_{i=1}^n x_i = 0\n",
    "\\tag{5}\n",
    "$$\n",
    "\n",
    "We now divide by $n$ and rearrange to isolate $\\beta_0$:\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "$$\n",
    "\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\n",
    "\\tag{6}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "Note: we can rewrite equation (4c) as\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n (y_i - \\hat{y}_i) = \\sum_{i=1}^n \\text{residuals} = 0,\n",
    "$$\n",
    "\n",
    "which is a nice thing to know.\n",
    "\n",
    "### slope\n",
    "\n",
    "Now let's move on to Eq. (3b):\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\beta_1} &= \\frac{\\partial}{\\partial \\beta_1} (y_i - \\hat{y}_i)^2 \\tag{7a} \\\\\n",
    "&= \\frac{\\partial}{\\partial \\beta_1} (y_i - \\beta_0 - \\beta_1 x_i)^2 \\tag{7b} \\\\\n",
    "&= -2 \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) x_i = 0 \\tag{7c} \\\\\n",
    "&= -2 \\sum_{i=1}^n (y_i - \\bar{y} + \\beta_1 \\bar{x} - \\beta_1 x_i) x_i = 0 \\tag{7d}\n",
    "\\end{align*}\n",
    "\n",
    "Eliminating the constant factor $2$ and expanding the summation, we get:\n",
    "\n",
    "$$\n",
    "-\\sum_{i=1}^n x_i y_i + \\sum_{i=1}^n x_i \\bar{y} - \\beta_1 \\sum_{i=1}^n x_i \\bar{x} + \\beta_1 \\sum_{i=1}^n x_i^2 = 0\n",
    "\\tag{8}\n",
    "$$\n",
    "\n",
    "Let's group the terms involving $\\beta_1$ on one side and the rest on the other side:\n",
    "\n",
    "$$\n",
    "\\beta_1 \\left( \\sum_{i=1}^n x_i^2 - \\sum_{i=1}^n x_i \\bar{x} \\right) = \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\bar{y}\n",
    "\\tag{9}\n",
    "$$\n",
    "\n",
    "Isolating $\\beta_1$, we have:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{\\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\bar{y}}{\\sum_{i=1}^n x_i^2 - \\sum_{i=1}^n x_i \\bar{x}} = \\frac{\\text{numerator}}{\\text{denominator}}\n",
    "\\tag{10}\n",
    "$$\n",
    "\n",
    "It's easier to interpret the numerator and denominator separately. To each we will add and subtract a term that will allow us to express them in simpler forms.\n",
    "\n",
    "Numerator:\n",
    "\n",
    "$$\n",
    "\\text{numerator} = \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\bar{y} + \\sum_{i=1}^n \\bar{x} y_i - \\sum_{i=1}^n \\bar{x} y_i\n",
    "\\tag{11}\n",
    "$$\n",
    "\n",
    "We express the third term thus:\n",
    "\n",
    "$$\n",
    "\\text{third term} = \\sum_{i=1}^n \\bar{x} y_i = \\bar{x} \\sum_{i=1}^n y_i = n \\bar{x} \\bar{y} = \\sum_{i=1}^n \\bar{x} \\bar{y}\n",
    "\\tag{12}\n",
    "$$\n",
    "\n",
    "The numerator now becomes:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{numerator} &= \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\bar{y} + \\sum_{i=1}^n \\bar{x} \\bar{y} - \\sum_{i=1}^n \\bar{x} y_i \\tag{13a} \\\\\n",
    "&= \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) \\tag{13b} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now the denominator:\n",
    "\n",
    "$$\n",
    "\\text{denominator} = \\sum_{i=1}^n x_i^2 - \\sum_{i=1}^n x_i \\bar{x} + \\sum_{i=1}^n x_i\\bar{x} - \\sum_{i=1}^n x_i\\bar{x}\n",
    "\\tag{14}\n",
    "$$\n",
    "\n",
    "We group the second and fourth terms, and express the third term thus:\n",
    "\n",
    "$$\n",
    "\\text{third term} = \\sum_{i=1}^n x_i \\bar{x} = \\bar{x} \\sum_{i=1}^n x_i = n \\bar{x}^2 = \\sum_{i=1}^n \\bar{x}^2\n",
    "\\tag{15}\n",
    "$$\n",
    "\n",
    "The denominator now becomes:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{denominator} &= \\sum_{i=1}^n x_i^2 - 2 \\sum_{i=1}^n x_i \\bar{x} + \\sum_{i=1}^n \\bar{x}^2 \\tag{16a} \\\\\n",
    "&= \\sum_{i=1}^n (x_i - \\bar{x})^2 \\tag{16b}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Putting it all together, we have:\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "$$\n",
    "\\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\n",
    "\\tag{17}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "## slope and correlation\n",
    "\n",
    "Let's divide both the numerator and denominator of Eq. (17) by $n-1$:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}\n",
    "\\tag{18}\n",
    "$$\n",
    "\n",
    "The numerator is the sample covariance $Cov(X, Y)$, and the denominator is the sample variance $Var(X)$:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{Cov(X, Y)}{Var(X)}\n",
    "\\tag{19}\n",
    "$$\n",
    "\n",
    "Now, we can express the covariance in terms of the correlation coefficient $\\rho_{X,Y}$ and the standard deviations $\\sigma_X$ and $\\sigma_Y$:\n",
    "\n",
    "$$\n",
    "Cov(X, Y) = \\rho_{X,Y} \\sigma_X \\sigma_Y\n",
    "\\tag{20}\n",
    "$$\n",
    "Substituting Eq. (20) into Eq. (19), we get:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{\\rho_{X,Y} \\sigma_X \\sigma_Y}{\\sigma_X^2}\n",
    "\\tag{21}\n",
    "$$\n",
    "\n",
    "And finally, we have:\n",
    "\n",
    "<div class=\"alert alert-primary\">\n",
    "$$\n",
    "\\beta_1 = \\rho_{X,Y} \\frac{\\sigma_Y}{\\sigma_X}\n",
    "\\tag{22}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "\n",
    "This shows that the slope of the regression line is directly proportional to the correlation coefficient. A higher absolute value of the correlation coefficient indicates a steeper slope, while a lower absolute value indicates a flatter slope."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
